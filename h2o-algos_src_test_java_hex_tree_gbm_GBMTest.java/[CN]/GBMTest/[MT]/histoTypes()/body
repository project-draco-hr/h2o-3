{
  Frame tfr=null;
  Key[] ksplits=null;
  GBMModel gbm=null;
  try {
    Scope.enter();
    tfr=parse_test_file("smalldata/covtype/covtype.20k.data");
    int resp=54;
    Scope.track(tfr.replace(resp,tfr.vecs()[resp].toCategoricalVec()));
    DKV.put(tfr);
    SplitFrame sf=new SplitFrame(tfr,new double[]{0.5,0.5},new Key[]{Key.make("train.hex"),Key.make("valid.hex")});
    sf.exec().get();
    ksplits=sf._destination_frames;
    SharedTreeModel.SharedTreeParameters.HistogramType[] histoType=SharedTreeModel.SharedTreeParameters.HistogramType.values();
    final int N=histoType.length;
    double[] loglosses=new double[N];
    for (int i=0; i < N; ++i) {
      GBMModel.GBMParameters parms=new GBMModel.GBMParameters();
      parms._train=ksplits[0];
      parms._valid=ksplits[1];
      parms._response_column=tfr.names()[resp];
      parms._learn_rate=0.05f;
      parms._histogram_type=histoType[i];
      parms._ntrees=10;
      parms._score_tree_interval=parms._ntrees;
      parms._max_depth=5;
      parms._seed=0xDECAFFEE;
      GBM job=new GBM(parms);
      gbm=job.trainModel().get();
      loglosses[i]=gbm._output._scored_valid[gbm._output._scored_valid.length - 1]._logloss;
      if (gbm != null)       gbm.delete();
    }
    for (int i=0; i < histoType.length; ++i) {
      Log.info("histoType: " + histoType[i] + " -> validation logloss: "+ loglosses[i]);
    }
    int idx=ArrayUtils.minIndex(loglosses);
    Log.info("Optimal randomization: " + histoType[idx]);
    assertTrue(4 == idx);
  }
  finally {
    if (gbm != null)     gbm.delete();
    if (tfr != null)     tfr.delete();
    if (ksplits[0] != null)     ksplits[0].remove();
    if (ksplits[1] != null)     ksplits[1].remove();
    Scope.exit();
  }
}
