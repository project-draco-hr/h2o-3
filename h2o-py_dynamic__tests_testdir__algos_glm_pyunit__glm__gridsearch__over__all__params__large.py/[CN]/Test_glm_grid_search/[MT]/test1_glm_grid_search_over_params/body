def test1_glm_grid_search_over_params(self):
    "\n        test1_glm_grid_search_over_params: test for condition 1 and performs the following:\n        a. grab all truely griddable parameters and randomly or manually set the parameter values.\n        b. Next, build H2O GLM models using grid search.  Count and make sure models\n           are only built for hyper-parameters set to legal values.  No model is built for bad hyper-parameters\n           values.  We should instead get a warning/error message printed out.\n        c. For each model built using grid search, we will extract the parameters used in building\n           that model and manually build a H2O GLM model.  Training metrics are calculated from the\n           gridsearch model and the manually built model.  If their metrics\n           differ by too much, print a warning message but don't fail the test.\n        d. we will check and make sure the models are built within the max_runtime_secs time limit that was set\n           for it as well.  If max_runtime_secs was exceeded, declare test failure.\n        "
    print('*******************************************************************************************')
    print(('test1_glm_grid_search_over_params for GLM ' + self.family))
    h2o.cluster_info()
    try:
        print('Hyper-parameters used here is {0}'.format(self.final_hyper_params_bad))
        grid_model = H2OGridSearch(H2OGeneralizedLinearEstimator(family=self.family, nfolds=self.nfolds), hyper_params=self.final_hyper_params_bad)
        grid_model.train(x=self.x_indices, y=self.y_index, training_frame=self.training1_data)
        self.correct_model_number = len(grid_model)
        if (not (self.correct_model_number == self.possible_number_models)):
            self.test_failed += 1
            self.test_failed_array[self.test_num] = 1
            print('test_glm_search_over_params for GLM failed: number of models built by gridsearch does not equal to all possible combinations of hyper-parameters')
        else:
            params_dict = dict()
            params_dict['family'] = self.family
            params_dict['nfolds'] = self.nfolds
            total_run_time_limits = 0.0
            true_run_time_limits = 0.0
            manual_run_runtime = 0.0
            for each_model in grid_model:
                params_list = grid_model.get_hyperparams_dict(each_model._id)
                params_list.update(params_dict)
                model_params = dict()
                if ('lambda' in list(params_list)):
                    params_list['Lambda'] = params_list['lambda']
                    del params_list['lambda']
                if ('max_runtime_secs' in params_list):
                    model_params['max_runtime_secs'] = params_list['max_runtime_secs']
                    del params_list['max_runtime_secs']
                if ('stopping_rounds' in params_list):
                    model_params['stopping_rounds'] = params_list['stopping_rounds']
                    del params_list['stopping_rounds']
                if ('stopping_tolerance' in params_list):
                    model_params['stopping_tolerance'] = params_list['stopping_tolerance']
                    del params_list['stopping_tolerance']
                manual_model = H2OGeneralizedLinearEstimator(**params_list)
                manual_model.train(x=self.x_indices, y=self.y_index, training_frame=self.training1_data, **model_params)
                model_runtime = pyunit_utils.find_grid_runtime([manual_model])
                manual_run_runtime += model_runtime
                summary_list = manual_model._model_json['output']['model_summary']
                iteration_num = summary_list.cell_values[0][summary_list.col_header.index('number_of_iterations')]
                if (model_params['max_runtime_secs'] > 0):
                    if ((model_params['max_runtime_secs'] < self.min_runtime_per_epoch) or (iteration_num <= 1)):
                        total_run_time_limits += model_runtime
                    else:
                        total_run_time_limits += model_params['max_runtime_secs']
                true_run_time_limits += model_params['max_runtime_secs']
                grid_model_metrics = each_model.model_performance(test_data=self.training2_data)
                manual_model_metrics = manual_model.model_performance(test_data=self.training2_data)
                if (not ((type(grid_model_metrics.mse()) == str) or (type(manual_model_metrics.mse()) == str))):
                    if ((abs(grid_model_metrics.mse()) > 0) and ((abs((grid_model_metrics.mse() - manual_model_metrics.mse())) / grid_model_metrics.mse()) > self.allowed_diff)):
                        print('test1_glm_grid_search_over_params for GLM warning: grid search model metric ({0}) and manually built H2O model metric ({1}) differ too much!'.format(grid_model_metrics.mse(), manual_model_metrics.mse()))
            total_run_time_limits = (max(total_run_time_limits, true_run_time_limits) * (1 + self.extra_time_fraction))
        if (not (self.correct_model_number == self.possible_number_models)):
            self.test_failed += 1
            self.test_failed_array[self.test_num] = 1
            print('test1_glm_grid_search_over_params for GLM failed: number of models built by gridsearch does not equal to all possible combinations of hyper-parameters')
        if (not (manual_run_runtime <= total_run_time_limits)):
            print('test1_glm_grid_search_over_params for GLM warning: allow time to build models: {0}, actual time taken: {1}'.format(total_run_time_limits, manual_run_runtime))
        self.test_num += 1
        if (self.test_failed == 0):
            print('test1_glm_grid_search_over_params for GLM has passed!')
    except:
        if (self.possible_number_models > 0):
            print('test1_glm_grid_search_over_params for GLM failed: exception was thrown for no reason.')
