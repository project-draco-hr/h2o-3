def test3_glm_grid_search(self):
    '\n        This test is used to test GridSearch with the following parameters:\n        1. Lambda = best_lambda value from test2\n        2. alpha = [0 0.5 0.99]\n        3. cross-validation with nfolds = 5, fold_assignment = "Random"\n\n        We will look at the best results from the grid search and compare it with H2O model built in test 1.\n\n        :return: None\n        '
    print('*******************************************************************************************')
    print('Test3: explores various parameter settings in training the GLM using GridSearch using solver ')
    h2o.cluster_info()
    hyper_parameters = {'alpha': [0, 0.5, 0.99], }
    model_h2o_grid_search = H2OGridSearch(H2OGeneralizedLinearEstimator(family=self.family, Lambda=self.best_lambda, nfolds=5, fold_assignment='Random'), hyper_parameters)
    model_h2o_grid_search.train(x=self.x_indices, y=self.y_index, training_frame=self.training_data_grid)
    temp_model = model_h2o_grid_search.sort_by('logloss(xval=True)')
    best_model_id = temp_model['Model Id'][0]
    self.best_grid_logloss = temp_model['logloss(xval=True)'][0]
    self.best_alpha = model_h2o_grid_search.get_hyperparams(best_model_id)
    best_model = h2o.get_model(best_model_id)
    best_model_test_metrics = best_model.model_performance(test_data=self.test_data)
    num_test_failed = self.test_failed
    self.test_failed = pyunit_utils.extract_comparison_attributes_and_print_multinomial(best_model, best_model_test_metrics, self.family, '\nTest3 Done!', test_model=self.test_template_model, test_model_metric=self.test_template_model_metrics, compare_att_str=['\nComparing intercept and weights ....', '\nComparing logloss from training data set ....', '\nComparing logloss from test data set ....', '\nComparing confusion matrices from training data set ....', '\nComparing confusion matrices from test data set ...', '\nComparing accuracy from training data set ....', '\nComparing accuracy from test data set ....'], h2o_att_str=['H2O grid search intercept and weights: \n', 'H2O grid search logloss from training data set: ', 'H2O grid search logloss from test data set', 'H2O grid search confusion matrix from training data set: \n', 'H2O grid search confusion matrix from test data set: \n', 'H2O grid search accuracy from training data set: ', 'H2O grid search accuracy from test data set: '], template_att_str=['H2O test1 template intercept and weights: \n', 'H2O test1 template logloss from training data set: ', 'H2O test1 template logloss from test data set: ', 'H2O test1 template confusion matrix from training data set: \n', 'H2O test1 template confusion matrix from test data set: \n', 'H2O test1 template accuracy from training data set: ', 'H2O test1 template accuracy from test data set: '], att_str_fail=['Intercept and weights are not equal!', 'Logloss from training data set differ too much!', 'Logloss from test dataset differ too much!', '', '', 'Accuracies from training data set differ too much!', 'Accuracies from test data set differ too much!'], att_str_success=['Intercept and weights are close enough!', 'Logloss from training data set are close enough!', 'Logloss from test data set are close enough!', '', '', 'Accuracies from training data set are close enough!', 'Accuracies from test data set are close enough!'], can_be_better_than_template=[True, True, True, True, True, True, True], just_print=[True, True, True, True, True, True, False], failed_test_number=self.test_failed, ignored_eps=self.ignored_eps, allowed_diff=self.allowed_diff)
    self.test_failed_array[self.test_num] += pyunit_utils.show_test_results('test_glm_grid_search_over_params', num_test_failed, self.test_failed)
    self.test_num += 1
