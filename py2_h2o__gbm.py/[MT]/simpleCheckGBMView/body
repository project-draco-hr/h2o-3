def simpleCheckGBMView(node=None, gbmv=None, noPrint=False, **kwargs):
    if (not node):
        node = h2o_nodes.nodes[0]
    if ('warnings' in gbmv):
        warnings = gbmv['warnings']
        for w in warnings:
            if (not noPrint):
                print '\nwarning:', w
            if (('Failed' in w) or ('failed' in w)):
                raise Exception(w)
    if ('cm' in gbmv):
        cm = gbmv['cm']
    else:
        if ('gbm_model' in gbmv):
            gbm_model = gbmv['gbm_model']
        else:
            raise Exception(('no gbm_model in gbmv? %s' % dump_json(gbmv)))
        cms = gbm_model['cms']
        print 'number of cms:', len(cms)
        print "FIX! need to add reporting of h2o's _perr per class error"
        print "cms[-1]['_arr']:", cms[(-1)]['_arr']
        print "cms[-1]['_predErr']:", cms[(-1)]['_predErr']
        print "cms[-1]['_classErr']:", cms[(-1)]['_classErr']
        cm = cms[(-1)]['_arr']
    scoresList = cm
    used_trees = gbm_model['N']
    errs = gbm_model['errs']
    print 'errs[0]:', errs[0]
    print 'errs[-1]:', errs[(-1)]
    print 'errs:', errs
    param_ntrees = kwargs.get('ntrees', None)
    if ((param_ntrees is not None) and (used_trees != param_ntrees)):
        raise Exception(('used_trees should == param_ntree. used_trees: %s' % used_trees))
    if (((used_trees + 1) != len(cms)) or ((used_trees + 1) != len(errs))):
        raise Exception(('len(cms): %s and len(errs): %s should be one more than N %s trees' % (len(cms), len(errs), used_trees)))
    totalScores = 0
    totalRight = 0
    classErrorPctList = []
    predictedClassDict = {}
    for (classIndex, s) in enumerate(scoresList):
        classSum = sum(s)
        if (classSum == 0):
            if (not noPrint):
                print 'class:', classIndex, 'classSum', classSum, '<- why 0?'
        else:
            classRightPct = (((s[classIndex] + 0.0) / classSum) * 100)
            totalRight += s[classIndex]
            classErrorPct = round((100 - classRightPct), 2)
            classErrorPctList.append(classErrorPct)
            if (not noPrint):
                print 'class:', classIndex, 'classSum', classSum, 'classErrorPct:', ('%4.2f' % classErrorPct)
            for (pIndex, p) in enumerate(s):
                if (pIndex not in predictedClassDict):
                    predictedClassDict[pIndex] = p
                else:
                    predictedClassDict[pIndex] += p
        totalScores += classSum
    if (not noPrint):
        print 'Predicted summary:'
        for (predictedClass, p) in predictedClassDict.items():
            print (str(predictedClass) + ':'), p
        print 'totalScores:', totalScores
        print 'totalRight:', totalRight
        if (totalScores != 0):
            pctRight = ((100.0 * totalRight) / totalScores)
        else:
            pctRight = 0.0
        pctWrong = (100 - pctRight)
        print 'pctRight:', ('%5.2f' % pctRight)
        print 'pctWrong:', ('%5.2f' % pctWrong)
    sample_rate = kwargs.get('sample_rate', None)
    validation = kwargs.get('validation', None)
    if ((sample_rate == 1) and (not validation)):
        pass
    elif ((totalScores <= 0) or (totalScores > 5000000000.0)):
        raise Exception('scores in GBMView seems wrong. scores:', scoresList)
    varimp = gbm_model['varimp']
    treeStats = gbm_model['treeStats']
    if (not treeStats):
        raise Exception(('treeStats not right?: %s' % dump_json(treeStats)))
    data_key = gbm_model['_dataKey']
    model_key = gbm_model['_key']
    classification_error = pctWrong
    if (not noPrint):
        if (('minLeaves' not in treeStats) or (not treeStats['minLeaves'])):
            raise Exception(('treeStats seems to be missing minLeaves %s' % dump_json(treeStats)))
        print '\n         Leaves: {0} / {1} / {2}\n          Depth: {3} / {4} / {5}\n            Err: {6:0.2f} %\n        '.format(treeStats['minLeaves'], treeStats['meanLeaves'], treeStats['maxLeaves'], treeStats['minDepth'], treeStats['meanDepth'], treeStats['maxDepth'], classification_error)
    dataInspect = h2o_cmd.runInspect(key=data_key)
    check_sandbox_for_errors()
    return (round(classification_error, 2), classErrorPctList, totalScores)
