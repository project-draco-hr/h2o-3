'\nThe H2O Python Module\n=====================\n\nThis module provides access to the H2O JVM (and extensions thereof), its objects, its\nmachine-learning algorithms, and modeling support (basic munging and feature generation)\ncapabilities.\n\nThe H2O JVM sports a web server such that all communication occurs on a socket (specified\nby an IP address and a port) via a series of REST calls (see connection.py for the REST\nlayer implementation and details). There is a single active connection to the H2O JVM at\nany one time, and this handle is stashed away out of sight in a singleton instance of\n:class:`H2OConnection` (this is the global  :envvar:`__H2OConn__`).\n\nThe H2O python module is not intended as a replacement for other popular machine learning\nmodules such as scikit-learn, pylearn2, and their ilk. This module is a complementary\ninterface to a modeling engine intended to make the transition of models from development\nto production as seamless as possible. Additionally, it is designed to bring H2O to a\nwider audience of data and machine learning devotees that work exclusively with Python\n(rather than R or scala or Java -- which are other popular interfaces that H2O supports),\nand are wanting another tool for building applications or doing data munging in a fast,\nscalable environment without any extra mental anguish about threads and parallelism.\n\n\nWhat is H2O?\n------------\n\nH2O is a piece of java software for data modeling and general computing. There are many\ndifferent views of the H2O software, but the primary view of H2O is that of a distributed\n(many machines), parallel (many CPUs), in memory (several hundred GBs Xmx) processing\nengine.\n\nThere are two levels of parallelism:\n\n    * within node\n    * across (or between) node.\n\nThe goal, remember, is to "simply" add more processors to a given problem in order to\nproduce a solution faster. The conceptual paradigm MapReduce (also known as\n"divide and conquer and combine") along with a good concurrent application structure\n(c.f. jsr166y and NonBlockingHashMap) enable this type of scaling in H2O (we\'re really\ncooking with gas now!).\n\nFor application developers and data scientists, the gritty details of thread-safety,\nalgorithm parallelism, and node coherence on a network are concealed by simple-to-use REST\ncalls that are all documented here. In addition, H2O is an open-source project under the\nApache v2 licence. All of the source code is on\n`github <https://github.com/h2oai/h2o-dev>`_, there is an active\n`google group mailing list <https://groups.google.com/forum/#!forum/h2ostream>`_, our\n`nightly tests <http://test.0xdata.com/>`_ are open for perusal, our `JIRA ticketing\nsystem <http://jira.0xdata.com>`_ is also open for public use. Last, but not least, we\nregularly engage the machine learning community all over the nation with a very busy\n`meetup schedule <http://h2o.ai/events/>`_ (so if you\'re not in The Valley, no sweat,\nwe\'re probably coming to you soon!), and finally, we host our very own `H2O World\nconference <http://h2o.ai/h2o-world/>`_. We also sometimes host hack-a-thons at our\ncampus in Mountain View, CA. Needless to say, there is a lot of support for the\napplication developer.\n\nIn order to make the most out of H2O, there are some key conceptual pieces that are helpful\nto know before getting started. Mainly, it\'s helpful to know about the different types of\nobjects that live in H2O and what the rules of engagement are in the context of the REST\nAPI (which is what any non-JVM interface is all about).\n\nLet\'s get started!\n\nThe H2O Object System\n+++++++++++++++++++++\n\nH2O sports a distributed key-value store (the "DKV"), which contains pointers to the\nvarious objects that make up the H2O ecosystem. The DKV is a kind of biosphere in that it\nencapsulates all shared objects (though, it may not encapsulate all objects). Some shared\nobjects are mutable by the client; some shared objects are read-only by the client, but\nmutable by H2O (e.g. a model being constructed will change over time); and actions by the\nclient may have side-effects on other clients (multi-tenancy is not a supported model of\nuse, but it is possible for multiple clients to attach to a single H2O cloud).\n\nBriefly, these objects are:\n\n     * :mod:`Key`:    A key is an entry in the DKV that maps to an object in H2O.\n\n     * :mod:`Frame`:  A Frame is a collection of Vec objects. It is a 2D array of elements.\n\n     * :mod:`Vec`:    A Vec is a collection of Chunk objects. It is a 1D array of elements.\n\n     * :mod:`Chunk`:  A Chunk holds a fraction of the BigData. It is a 1D array of elements.\n\n     * :mod:`ModelMetrics`:   A collection of metrics for a given category of model.\n\n     * :mod:`Model`:  A model is an immutable object having `predict` and `metrics` methods.\n\n     * :mod:`Job`:    A Job is a non-blocking task that performs a finite amount of work.\n\nMany of these objects have no meaning to an end python user, but in order to make sense of\nthe objects available in this module it is helpful to understand how these objects map to\nobjects in the JVM (because after all, this module is an interface that allows the\nmanipulation of a distributed system).\n\n\nObjects In This Module\n----------------------\n\nThe objects that are of primary concern to the python user are (in order) Keys, Frames,\nVecs, Models, ModelMetrics, and to a lesser extent Jobs. Each of these objects are\ndescribed in greater detail throughout this documentation, but a few brief notes are\nwarranted here.\n\n\nH2OFrame\n++++++++\n\nAn H2OFrame is 2D array of uniformly-typed columns. Data in H2O is compressed (often\nachieving 2-4x better compression the gzip on disk) and is held in the JVM heap (i.e.\ndata is "in memory"), and *not* in the python process local memory.. The H2OFrame is an\niterable (supporting list comprehensions) wrapper around a list of H2OVec objects. All an\nH2OFrame object is, therefore, is a wrapper on a list that supports various types of operations\nthat may or may not be lazy. Here\'s an example showing how a list comprehension is combined\nwith lazy expressions to compute the column means for all columns in the H2OFrame::\n\n  >>> df = h2o.import_frame(path="smalldata/logreg/prostate.csv")  # import prostate data\n  >>>\n  >>> colmeans = [v.mean().eager() for v in a]                     # compute column means eagerly\n  >>>\n  >>> colmeans                                                     # print the results\n  [5.843333333333335, 3.0540000000000007, 3.7586666666666693, 1.1986666666666672]\n\nLazy expressions will be discussed in detail in the coming sections, but their primary\npurpose is to cut down on the chatter between the client (a.k.a this python interface) and\nH2O. Lazy expressions are\n`Katamari\'d <http://www.urbandictionary.com/define.php?term=Katamari>`_ together and only\never evaluated when some piece of output is requested (e.g. print-to-screen).\n\nThe set of operations on an H2OFrame is described in a chapter devoted to this object, but\nsuffice it to say that this set of operations closely resembles those that may be\nperformed on an R data.frame. This includes all manner of slicing (with complex\nconditionals), broadcasting operations, and a slew of math operations for transforming and\nmutating a Frame (the actual Big Data sitting in the H2O cloud). The semantics for\nmodifying a Frame closely resembles R\'s copy-on-modify semantics, except when it comes\nto mutating a Frame in place. For example, it\'s possible to assign all occurrences of the\nnumber `0` in a column to missing (or `NA` in R parlance) as demonstrated in the following\nsnippet::\n\n\n  >>> df = h2o.import_frame(path="smalldata/logreg/prostate.csv")  # import prostate data\n  >>>\n  >>> vol = df[\'VOL\']                                              # select the VOL column\n  >>>\n  >>> vol[vol == 0] = None                                         # 0 VOL means \'missing\'\n\nAfter this operation, `vol` has been permanently mutated in place (it is not a copy!).\n\nH2OVec\n++++++\nAn H2OVec is a single column of data that is uniformly typed and possibly lazily computed.\n\nExpr\n++++\n\n* Lazy expressions...\n\nModels\n++++++\n\nThe model-building experience with this module is unique, and is not the same experience\nfor those coming from a background in scikit-learn.\n\nRather than have each model define its own class, each model will belong to one of the following\ncategories:\n\n    * Regression\n    * Binomial\n    * Multinomial\n    * Clustering\n\nThis is not an entirely representative list of model categories (e.g., what about Time Series,\nand Grid Search, or PCA?); but it represents the core set of underlying model categories\nthat form the foundation and current state of modeling in H2O.\n\n\n* No explicit model objects -- have model categories\n* How to create new models\n* train and validation data\n* parameter specification\n* categoricals are dealt with internally (no need to one-hot expand them!)\n* what about categoricals in my response?\n* what about an integral response column that I want to do classification on\n* See more on the chapter on Models\n\nMetrics\n+++++++\n\n* Metrics for different types of model categories\n* See more in the chapter on Metrics\n\n'
__version__ = '0.0.0a5'
from h2o import *
from model import *
from frame import H2OFrame
from frame import H2OVec
from two_dim_table import H2OTwoDimTable
__all__ = ['H2OFrame', 'H2OConnection', 'H2OVec', 'H2OTwoDimTable']
