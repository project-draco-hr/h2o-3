def confusion_matrix(self, metrics=None, thresholds=None, train=False, valid=False, xval=False):
    u'\n        Get the confusion matrix for the specified metrics/thresholds.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where the\n        keys are "train", "valid", and "xval"\n\n        Parameters\n        ----------\n          metrics : str, list\n            One or more of "min_per_class_accuracy", "absolute_mcc", "tnr", "fnr", "fpr",\n            "tpr", "precision", "accuracy", "f0point5", "f2", "f1".\n\n          thresholds : list, optional\n            If None, then the thresholds in this set of metrics will be used.\n\n          train : bool, optional\n            If True, return the confusion_matrix for the training data.\n\n          valid : bool, optional\n            If True, return the confusion_matrix for the validation data.\n\n          xval : bool, optional\n            If True, return the confusion_matrix for each of the cross-validated splits.\n\n        Returns\n        -------\n          The metric values for the specified key(s).\n        '
    tm = ModelBase._get_metrics(self, train, valid, xval)
    m = {}
    for (k, v) in viewitems(tm):
        m[k] = (None if (v is None) else v.confusion_matrix(metrics=metrics, thresholds=thresholds))
    return (list(m.values())[0] if (len(m) == 1) else m)
