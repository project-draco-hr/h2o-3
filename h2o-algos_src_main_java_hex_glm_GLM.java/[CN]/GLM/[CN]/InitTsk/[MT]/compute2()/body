{
  new YMUTask(_dinfo,_response.makeZero(),new H2OCallback<YMUTask>(){
    @Override public void callback(    final YMUTask ymut){
      _rowFilter=ymut._fVec;
      if (ymut._nobs == 0)       error("training_frame","Got no data to run on after filtering out the rows with missing values.");
      if (ymut._yMin == ymut._yMax)       error("response","Can not run glm on dataset with constant response. Response == " + ymut._yMin + " for all rows in the dataset after filtering out rows with NAs, got "+ ymut._nobs+ " of rows out of "+ _dinfo._adaptedFrame.numRows()+ " rows total.");
      long nobs=ymut._nobs;
      if (ymut._nobs < _dinfo._adaptedFrame.numRows() >> 1) {
        warn("training_frame","Dataset has less than 1/2 of the data after filtering out rows with NAs");
      }
      final double[] beta=MemoryManager.malloc8d(_dinfo.fullN() + 1);
      beta[beta.length - 1]=_parms.link(ymut._ymu);
      if (_bc._betaStart == null)       _bc.setBetaStart(beta);
      GLMGradientTask gt=new GLMTask.GLMGradientTask(_dinfo,_parms,0,beta,1.0 / nobs,new H2OCallback<GLMGradientTask>(InitTsk.this){
        @Override public void callback(        GLMGradientTask gt){
          double lmax=lmax(gt);
          if (beta == _bc._betaStart)           _tInfos[_foldId]=new GLMTaskInfo(_dest,0,ymut._nobs,ymut._ymu,lmax,_bc._betaStart,new GradientInfo(gt._objVal,gt._gradient),gt._objVal);
 else           _tInfos[_foldId]=new GLMTaskInfo(_dest,0,ymut._nobs,ymut._ymu,lmax,_bc._betaStart,null,Double.POSITIVE_INFINITY);
        }
      }
).dfork(_dinfo._adaptedFrame);
    }
  }
).dfork(_dinfo._adaptedFrame);
}
