{
  H2OCountedCompleter cmp=(H2OCountedCompleter)getCompleter();
  cmp.addToPendingCount(1);
  final double[] fullBeta;
  if (newBeta == null) {
    fullBeta=MemoryManager.malloc8d(_dinfo.fullN() + 1);
    fullBeta[fullBeta.length - 1]=_parms.linkInv(_taskInfo._ymu);
  }
 else   fullBeta=expandVec(newBeta,_activeCols,_dinfo.fullN() + 1);
  new GLMGradientTask(_dinfo,_parms,_parms._lambda[_lambdaId] * (1 - _parms._alpha[0]),fullBeta,1.0 / _taskInfo._nobs,new H2O.H2OCallback<GLMGradientTask>(cmp){
    @Override public String toString(){
      return "checkKKTAndComplete.Callback, completer = " + getCompleter() == null ? "null" : getCompleter().toString();
    }
    @Override public void callback(    final GLMGradientTask glrt){
      final double[] grad=glrt._gradient;
      if (ArrayUtils.hasNaNsOrInfs(grad)) {
        if (!failedLineSearch) {
          LogInfo("Check KKT got NaNs. Invoking line search");
          getCompleter().addToPendingCount(1);
          new GLMLineSearchTask(_activeData,_parms,1.0 / _taskInfo._nobs,_taskInfo._beta,ArrayUtils.subtract(contractVec(fullBeta,_activeCols),_taskInfo._beta),LINE_SEARCH_STEP,NUM_LINE_SEARCH_STEPS,new LineSearchIteration(getCompleter())).asyncExec(_activeData._adaptedFrame);
          ;
          return;
        }
 else {
          LogInfo("got NaNs/Infs in gradient at lambda " + _parms._lambda[_lambdaId]);
        }
      }
      double[] subgrad=grad.clone();
      ADMM.subgrad(_parms._alpha[0] * _parms._lambda[_lambdaId],fullBeta,subgrad);
      double err=GLM_GRAD_EPS;
      if (!failedLineSearch && _activeCols != null) {
        for (        int c : _activeCols)         if (subgrad[c] > err)         err=subgrad[c];
 else         if (subgrad[c] < -err)         err=-subgrad[c];
        int[] failedCols=new int[64];
        int fcnt=0;
        for (int i=0; i < grad.length - 1; ++i) {
          if (Arrays.binarySearch(_activeCols,i) >= 0)           continue;
          if (subgrad[i] > err || -subgrad[i] > err) {
            if (fcnt == failedCols.length)             failedCols=Arrays.copyOf(failedCols,failedCols.length << 1);
            failedCols[fcnt++]=i;
          }
        }
        if (fcnt > 0) {
          final int n=_activeCols.length;
          int[] oldCols=_activeCols;
          _activeCols=Arrays.copyOf(_activeCols,_activeCols.length + fcnt);
          for (int i=0; i < fcnt; ++i)           _activeCols[n + i]=failedCols[i];
          Arrays.sort(_activeCols);
          _taskInfo._beta=contractVec(glrt._beta,_activeCols);
          LogInfo(fcnt + " variables failed KKT conditions check! Adding them to the model and continuing computation.(grad_eps = " + err+ ", activeCols = "+ (_activeCols.length > 100 ? "lost" : Arrays.toString(_activeCols)));
          _activeData=_dinfo.filterExpandedColumns(_activeCols);
          getCompleter().addToPendingCount(1);
          new GLMIterationTask(GLM.this._key,_activeData,_parms._lambda[_lambdaId] * (1 - _parms._alpha[0]),_parms,true,contractVec(glrt._beta,_activeCols),_taskInfo._ymu,ModelUtils.DEFAULT_THRESHOLDS,new Iteration(getCompleter(),false)).asyncExec(_activeData._adaptedFrame);
          return;
        }
      }
      _taskInfo._beta=glrt._beta;
      _taskInfo._ginfo=new GradientInfo(glrt._objVal,glrt._gradient);
      _taskInfo._objVal=glrt._objVal + (1 - _parms._alpha[0]) * ArrayUtils.l1norm(glrt._beta,_activeData._intercept);
      setSubmodel(newBeta,glrt._val,(H2OCountedCompleter)getCompleter().getCompleter());
    }
  }
).setValidate(_taskInfo._ymu,true).asyncExec(_dinfo._adaptedFrame);
}
