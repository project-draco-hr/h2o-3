{
  H2O.H2OCountedCompleter cmp=(H2O.H2OCountedCompleter)getCompleter();
  cmp.addToPendingCount(1);
  final double[] fullBeta;
  if (newBeta == null) {
    fullBeta=MemoryManager.malloc8d(_taskInfo._dinfo.fullN() + 1);
    fullBeta[fullBeta.length - 1]=_taskInfo._params.linkInv(_taskInfo._ymu);
  }
 else   fullBeta=expandVec(newBeta,_activeCols,_taskInfo._dinfo.fullN() + 1);
  new GLMTask.GLMGradientTask(_taskInfo._dinfo,_taskInfo._params,_currentLambda * (1 - _taskInfo._params._alpha[0]),fullBeta,1.0 / _taskInfo._nobs,new H2O.H2OCallback<GLMGradientTask>(cmp){
    @Override public String toString(){
      return "checkKKTAndComplete.Callback, completer = " + getCompleter() == null ? "null" : getCompleter().toString();
    }
    @Override public void callback(    final GLMGradientTask glrt){
      final double[] grad=glrt._gradient;
      if (ArrayUtils.hasNaNsOrInfs(grad)) {
        if (!failedLineSearch) {
          LogInfo("Check KKT got NaNs. Invoking line search");
          _taskInfo._params._higher_accuracy=true;
          getCompleter().addToPendingCount(1);
          new GLMTask.GLMLineSearchTask(_activeData,_taskInfo._params._alpha[0],_currentLambda,_taskInfo._params,1.0 / _taskInfo._nobs,_lastResult._beta,ArrayUtils.subtract(contractVec(fullBeta,_activeCols),_lastResult._beta),LINE_SEARCH_STEP,NUM_LINE_SEARCH_STEPS,new LineSearchIteration(getCompleter())).asyncExec(_activeData._adaptedFrame);
          ;
          return;
        }
 else {
          LogInfo("got NaNs/Infs in gradient at lambda " + _currentLambda);
        }
      }
      double[] subgrad=grad.clone();
      ADMMSolver.subgrad(_taskInfo._params._alpha[0],_currentLambda,fullBeta,subgrad);
      double err=GLM_GRAD_EPS;
      if (!failedLineSearch && _activeCols != null) {
        for (        int c : _activeCols)         if (subgrad[c] > err)         err=subgrad[c];
 else         if (subgrad[c] < -err)         err=-subgrad[c];
        int[] failedCols=new int[64];
        int fcnt=0;
        for (int i=0; i < grad.length - 1; ++i) {
          if (Arrays.binarySearch(_activeCols,i) >= 0)           continue;
          if (subgrad[i] > err || -subgrad[i] > err) {
            if (fcnt == failedCols.length)             failedCols=Arrays.copyOf(failedCols,failedCols.length << 1);
            failedCols[fcnt++]=i;
          }
        }
        if (fcnt > 0) {
          final int n=_activeCols.length;
          int[] oldCols=_activeCols;
          _activeCols=Arrays.copyOf(_activeCols,_activeCols.length + fcnt);
          for (int i=0; i < fcnt; ++i)           _activeCols[n + i]=failedCols[i];
          if (_lastResult != null)           _lastResult=new IterationInfo(_lastResult._iter,resizeVec(_lastResult._beta,_activeCols,oldCols,_taskInfo._dinfo.fullN() + 1),_lastResult._objval,_lastResult._pen);
          Arrays.sort(_activeCols);
          LogInfo(fcnt + " variables failed KKT conditions check! Adding them to the model and continuing computation.(grad_eps = " + err+ ", activeCols = "+ (_activeCols.length > 100 ? "lost" : Arrays.toString(_activeCols)));
          _activeData=_taskInfo._dinfo.filterExpandedColumns(_activeCols);
          getCompleter().addToPendingCount(1);
          new GLMIterationTask(_jobKey,_activeData,_currentLambda * (1 - _taskInfo._params._alpha[0]),_taskInfo._params,true,contractVec(glrt._beta,_activeCols),_taskInfo._ymu,1.0 / _taskInfo._nobs,_taskInfo._thresholds,new Iteration(getCompleter(),false)).asyncExec(_activeData._adaptedFrame);
          return;
        }
      }
      _taskInfo._beta=glrt._beta;
      _taskInfo._ginfo=new GradientInfo(glrt._objVal,glrt._gradient);
      _taskInfo._objVal=_lastResult._objval;
      _taskInfo._iter=_iter;
      int diff=MAX_ITERATIONS_PER_LAMBDA - _iter + _taskInfo._iter;
      if (diff > 0)       new Job.ProgressUpdate(diff).fork(_progressKey);
      setSubmodel(newBeta,glrt._val,(H2O.H2OCountedCompleter)getCompleter().getCompleter());
    }
  }
).setValidate(_taskInfo._ymu,true).asyncExec(_taskInfo._dinfo._adaptedFrame);
}
