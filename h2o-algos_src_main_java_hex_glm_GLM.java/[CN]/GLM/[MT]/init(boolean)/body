{
  super.init(expensive);
  _parms.validate(this);
  if (expensive) {
    if (_parms._link == Link.family_default)     _parms._link=_parms._family.defaultLink;
    _dinfo=new DataInfo(Key.make(),_train,_valid,1,_parms._use_all_factor_levels || _parms._lambda_search,_parms._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE,DataInfo.TransformType.NONE,true);
    DKV.put(_dinfo._key,_dinfo);
    double[] betaStart=null;
    double[] betaGiven=null;
    double[] betaLB=null;
    double[] betaUB=null;
    double[] rho=null;
    if (_parms._beta_constraint != null) {
      Frame beta_constraints=_parms._beta_constraint.get();
      Vec v=beta_constraints.vec("names");
      String[] dom;
      int[] map;
      if (v.isString()) {
        dom=new String[(int)v.length()];
        map=new int[dom.length];
        ValueString vs=new ValueString();
        for (int i=0; i < dom.length; ++i) {
          dom[i]=v.atStr(vs,i).toString();
          map[i]=i;
        }
      }
 else       if (v.isEnum()) {
        dom=v.domain();
        map=FrameUtils.asInts(v);
      }
 else       throw new IllegalArgumentException("Illegal beta constraints file, names column expected to contain column names (strings)");
      String[] names=ArrayUtils.append(_dinfo.coefNames(),"Intercept");
      if (!Arrays.deepEquals(dom,names)) {
        HashMap<String,Integer> m=new HashMap<String,Integer>();
        for (int i=0; i < names.length; ++i)         m.put(names[i],i);
        int[] newMap=MemoryManager.malloc4(dom.length);
        for (int i=0; i < map.length; ++i) {
          Integer I=m.get(dom[map[i]]);
          if (I == null)           throw new IllegalArgumentException("Unrecognized coefficient name in beta-constraint file, unknown name '" + dom[map[i]] + "'");
          newMap[i]=I == null ? -1 : I;
        }
        map=newMap;
      }
      final int numoff=_dinfo.numStart();
      if ((v=beta_constraints.vec("beta_start")) != null) {
        betaStart=MemoryManager.malloc8d(_dinfo.fullN() + (_dinfo._intercept ? 1 : 0));
        for (int i=0; i < (int)v.length(); ++i)         betaStart[map == null ? i : map[i]]=v.at(i);
      }
      if ((v=beta_constraints.vec("beta_given")) != null) {
        betaGiven=MemoryManager.malloc8d(_dinfo.fullN() + (_dinfo._intercept ? 1 : 0));
        for (int i=0; i < (int)v.length(); ++i)         betaGiven[map == null ? i : map[i]]=v.at(i);
        if (betaStart == null)         betaStart=betaGiven;
      }
      if ((v=beta_constraints.vec("upper_bounds")) != null) {
        betaUB=MemoryManager.malloc8d(_dinfo.fullN() + (_dinfo._intercept ? 1 : 0));
        Arrays.fill(betaUB,Double.POSITIVE_INFINITY);
        for (int i=0; i < (int)v.length(); ++i)         betaUB[map == null ? i : map[i]]=v.at(i);
      }
      if ((v=beta_constraints.vec("lower_bounds")) != null) {
        betaLB=MemoryManager.malloc8d(_dinfo.fullN() + (_dinfo._intercept ? 1 : 0));
        Arrays.fill(betaLB,Double.NEGATIVE_INFINITY);
        for (int i=0; i < (int)v.length(); ++i)         betaLB[map == null ? i : map[i]]=v.at(i);
      }
      if ((v=beta_constraints.vec("rho")) != null) {
        rho=MemoryManager.malloc8d(_dinfo.fullN() + (_dinfo._intercept ? 1 : 0));
        for (int i=0; i < (int)v.length(); ++i)         rho[map == null ? i : map[i]]=v.at(i);
      }
      if (_dinfo._normMul != null) {
        double normG=0, normS=0;
        for (int i=numoff; i < _dinfo.fullN(); ++i) {
          double dd=_dinfo._normMul[i - numoff];
          double d=1.0 / dd;
          if (betaUB != null && !Double.isInfinite(betaUB[i]))           betaUB[i]*=d;
          if (betaLB != null && !Double.isInfinite(betaUB[i]))           betaLB[i]*=d;
          if (betaGiven != null) {
            normG+=betaGiven[i] * dd;
            betaGiven[i]*=d;
          }
          if (betaStart != null) {
            normS+=betaStart[i] * dd;
            betaStart[i]*=d;
          }
        }
        if (_dinfo._intercept) {
          int n=_dinfo.fullN();
          if (betaGiven != null)           betaGiven[n]-=normG;
          if (betaStart != null)           betaStart[n]-=normS;
        }
      }
      _bc.setBetaStart(betaStart).setLowerBounds(betaLB).setUpperBounds(betaUB).setProximalPenalty(betaGiven,rho);
    }
    _tInfos=new GLMTaskInfo[_parms._n_folds + 1];
    InitTsk itsk=new InitTsk(0,_dinfo._intercept,null);
    H2O.submitTask(itsk).join();
    if (itsk._ymut._nobs == 0)     error("training_frame","Got no data to run on after filtering out the rows with missing values.");
    if (itsk._ymut._yMin == itsk._ymut._yMax)     error("response","Can not run glm on dataset with constant response. Response == " + itsk._ymut._yMin + " for all rows in the dataset after filtering out rows with NAs, got "+ itsk._ymut._nobs+ " of rows out of "+ _dinfo._adaptedFrame.numRows()+ " rows total.");
    if (itsk._ymut._nobs < (_dinfo._adaptedFrame.numRows() >> 1)) {
      warn("training_frame","Dataset has less than 1/2 of the data after filtering out rows with NAs");
    }
    GLMGradientTask gtBetastart=itsk._gtBetaStart != null ? itsk._gtBetaStart : itsk._gtNull;
    double lmax=lmax(itsk._gtNull);
    double l1pen=_parms._alpha[0] * lmax * ArrayUtils.l1norm(_bc._betaStart,_dinfo._intercept);
    _tInfos[0]=new GLMTaskInfo(_dest,0,itsk._ymut._nobs,itsk._ymut._ymu,lmax,_bc._betaStart,new GradientInfo(gtBetastart._objVal,gtBetastart._gradient),gtBetastart._objVal + l1pen);
    if (_parms._lambda != null) {
      ArrayUtils.mult(_parms._lambda,-1);
      Arrays.sort(_parms._lambda);
      ArrayUtils.mult(_parms._lambda,-1);
      int i=0;
      while (i < _parms._lambda.length && _parms._lambda[i] > _tInfos[0]._lambdaMax)       ++i;
      if (i == _parms._lambda.length)       error("lambda","All passed lambda values are > lambda_max = " + _tInfos[0]._lambdaMax + ", nothing to compute.");
      if (i > 0) {
        _parms._lambda=Arrays.copyOfRange(_parms._lambda,i,_parms._lambda.length);
        warn("lambda","removed " + i + " lambda values which were greater than lambda_max = "+ _tInfos[0]._lambdaMax);
      }
    }
 else {
      if (_parms._lambda_search) {
        if (_parms._nlambdas == 1)         error("nlambdas","Number of lambdas must be > 1 when running with lambda_search!");
        if (_parms._lambda_min_ratio == -1)         _parms._lambda_min_ratio=_tInfos[0]._nobs > 25 * _dinfo.fullN() ? 1e-4 : 1e-2;
        final double d=Math.pow(_parms._lambda_min_ratio,1.0 / (_parms._nlambdas - 1));
        _parms._lambda=MemoryManager.malloc8d(_parms._nlambdas);
        _parms._lambda[0]=_tInfos[0]._lambdaMax;
        for (int i=1; i < _parms._lambda.length; ++i)         _parms._lambda[i]=_parms._lambda[i - 1] * d;
      }
 else       _parms._lambda=new double[]{_tInfos[0]._lambdaMax * (_dinfo.fullN() < (_tInfos[0]._nobs >> 4) ? 1e-3 : 1e-1)};
    }
    GLMModel m=new GLMModel(_dest,_parms,new GLMOutput(GLM.this),_dinfo,_tInfos[0]._ymu,_tInfos[0]._lambdaMax,_tInfos[0]._nobs,ModelUtils.DEFAULT_THRESHOLDS);
    m.delete_and_lock(GLM.this._key);
    m.adaptTestForTrain(_valid,true);
    if (_valid != null)     _validDinfo=new DataInfo(Key.make(),_valid,null,1,_parms._use_all_factor_levels || _parms._lambda_search,_parms._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE,DataInfo.TransformType.NONE,true);
    if (_parms._lambda_search)     setSubmodel(_dest,0,_bc._betaStart,gtBetastart._val,null,null);
  }
}
