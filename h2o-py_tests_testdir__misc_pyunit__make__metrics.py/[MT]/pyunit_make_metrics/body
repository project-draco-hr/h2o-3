def pyunit_make_metrics():
    fr = h2o.import_file(pyunit_utils.locate(u'smalldata/logreg/prostate.csv'))
    fr[u'CAPSULE'] = fr[u'CAPSULE'].asfactor()
    fr[u'RACE'] = fr[u'RACE'].asfactor()
    fr.describe()
    response = u'AGE'
    predictors = list((set(fr.names) - {u'ID', response}))
    print(u'\n\n======= REGRESSION ========\n')
    for distr in [u'gaussian', u'poisson', u'laplace', u'gamma']:
        print((u'distribution: %s' % distr))
        model = H2OGradientBoostingEstimator(distribution=distr, ntrees=2, max_depth=3, min_rows=1, learn_rate=0.1, nbins=20)
        model.train(x=predictors, y=response, training_frame=fr)
        predicted = h2o.assign(model.predict(fr), u'pred')
        actual = fr[response]
        m0 = model.model_performance(train=True)
        m1 = h2o.make_metrics(predicted, actual, distribution=distr)
        m2 = h2o.make_metrics(predicted, actual)
        print(u'model performance:')
        print(m0)
        print((u'make_metrics (distribution=%s):' % distr))
        print(m1)
        print(u'make_metrics (distribution=None):')
        print(m2)
        assert (abs((m0.mae() - m1.mae())) < 1e-05)
        assert (abs((m0.mse() - m1.mse())) < 1e-05)
        assert (abs((m0.rmse() - m1.rmse())) < 1e-05)
        assert (abs((m0.mean_residual_deviance() - m1.mean_residual_deviance())) < 1e-05)
        assert (abs((m0.rmsle() - m1.rmsle())) < 1e-05)
        assert (abs((m2.mae() - m1.mae())) < 1e-05)
        assert (abs((m2.mse() - m1.mse())) < 1e-05)
        assert (abs((m2.rmse() - m1.rmse())) < 1e-05)
        assert ((abs((m1.mean_residual_deviance() - m2.mean_residual_deviance())) < 1e-07) == (distr == u'gaussian'))
        assert (abs((m2.rmsle() - m1.rmsle())) < 1e-05)
    print(u'\n\n======= BINOMIAL ========\n')
    response = u'CAPSULE'
    predictors = list((set(fr.names) - {u'ID', response}))
    model = H2OGradientBoostingEstimator()
    model.train(x=predictors, y=response, distribution=u'bernoulli', training_frame=fr, ntrees=2, max_depth=3, min_rows=1, learn_rate=0.01, nbins=20)
    predicted = h2o.assign(model.predict(fr)[2], u'pred')
    actual = h2o.assign(fr[response].asfactor(), u'act')
    domain = [u'0', u'1']
    m0 = model.model_performance(train=True)
    m1 = h2o.make_metrics(predicted, actual, domain=domain)
    m2 = h2o.make_metrics(predicted, actual)
    print(u'm0:')
    print(m0)
    print(u'm1:')
    print(m1)
    print(u'm2:')
    print(m2)
    assert (abs((m0.auc() - m1.auc())) < 1e-05)
    assert (abs((m0.mse() - m1.mse())) < 1e-05)
    assert (abs((m0.rmse() - m1.rmse())) < 1e-05)
    assert (abs((m0.logloss() - m1.logloss())) < 1e-05)
    assert (abs((m0.mean_per_class_error()[0][1] - m1.mean_per_class_error()[0][1])) < 1e-05)
    assert (abs((m2.auc() - m1.auc())) < 1e-05)
    assert (abs((m2.mse() - m1.mse())) < 1e-05)
    assert (abs((m2.rmse() - m1.rmse())) < 1e-05)
    assert (abs((m2.logloss() - m1.logloss())) < 1e-05)
    assert (abs((m2.mean_per_class_error()[0][1] - m1.mean_per_class_error()[0][1])) < 1e-05)
    print(u'\n\n======= MULTINOMIAL ========\n')
    response = u'RACE'
    predictors = list((set(fr.names) - {u'ID', response}))
    model = H2OGradientBoostingEstimator()
    model.train(x=predictors, y=response, distribution=u'multinomial', training_frame=fr, ntrees=2, max_depth=3, min_rows=1, learn_rate=0.01, nbins=20)
    predicted = h2o.assign(model.predict(fr)[1:], u'pred')
    actual = h2o.assign(fr[response].asfactor(), u'act')
    domain = fr[response].levels()[0]
    m0 = model.model_performance(train=True)
    m1 = h2o.make_metrics(predicted, actual, domain=domain)
    m2 = h2o.make_metrics(predicted, actual)
    assert (abs((m0.mse() - m1.mse())) < 1e-05)
    assert (abs((m0.rmse() - m1.rmse())) < 1e-05)
    assert (abs((m0.logloss() - m1.logloss())) < 1e-05)
    assert (abs((m0.mean_per_class_error() - m1.mean_per_class_error())) < 1e-05)
    assert (abs((m2.mse() - m1.mse())) < 1e-05)
    assert (abs((m2.rmse() - m1.rmse())) < 1e-05)
    assert (abs((m2.logloss() - m1.logloss())) < 1e-05)
    assert (abs((m2.mean_per_class_error() - m1.mean_per_class_error())) < 1e-05)
