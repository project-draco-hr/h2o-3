print '\njenkins_h2o_port_allocate....'
import socket, os, subprocess
USED_HOSTNAMES = ['mr-0xb1', 'mr-0xb4', 'mr-0x2', 'mr-0x3', 'mr-0x4', 'mr-0x5', 'mr-0x6', 'mr-0x7', 'mr-0x8', 'mr-0x9', 'mr-0x10', 'mr-0xd4', 'mr-0xd5', 'mr-0xd6', 'mr-0xd7', 'mr-0xd8', 'mr-0xd9', 'mr-0xd10', 'Kevin-Ubuntu3']
PORTS_PER_SLOT = 10
DEFAULT_BASE_PORT = 54340
EXECUTOR_NUM = 8
if (__name__ == '__main__'):
    jenkins_h2o_port_allocate()
'\nThis auto-magics the manual allocation I did when parallelized the current 8-way jenkins jobs, \n2 per machine, on the jenkins mr-0xd4 that dispatches to mr-0xd5 thru mr-0xd9\n\nThe rationale for a global allocate requires understanding what machines a jenkins master/slave can be on, \nand what machines they send h2o jars to.\n\nat 0xdata:\n\nA jenkins master is a member of a group of machines. Jenkins can send the python or other test to another slave machine, and then the test can dispatch h2o either locally, or to other machines in the group. \n\nit can target h2o.jar\'s anywhere in that group, or dispatch a job to a slave in that group that might do the same.\n\nWe currently have two such groups, with one jenkins master in each group (mr-0xb4 and mr-0xd4)\n(update: let\'s just say it\'s all one big group. Not worth optimizing for subgroup knowlege)\nSo using \n    (hostname offset in the list of total hostnames)  * (EXECUTOR_NUMBER-1 * PORTS_PER_SLOT)\n\nWill give a unique offset from the default 54340 base, for the job, regardless of which jenkins (master or slave) starts it in the group and where the h2o targest are (which is controlled by the config.json used in the job)\n\nall cloud builds done in a job (one or more) use the same offset.\n\nDispatching tests from your laptop..will they collide with jenkins?\nIf the host machine is not in the list, like a laptop, then the offset is 0. (54340 will be used). I suppose jenkins could shift it\'s base_port to be at least 10 above 54340, so existing scripts that users have, that use 54340, won\'t be stepped on by jenkins. 54340 could be the jenkins base port.\n\nEC2:\nI suppose if the tests are used in ec2, we only do one h2o jar per machine, (or multijvm) so no conflict if 54340 is used. (or 54340). We typically want fast EC2 results, so don\'t overload target machines?. I suppose an EC2 machine list could be created in this script if we started overloading EC2 machines also\n\nPORTS_PER_SLOT is 10 right now, since the most a job will do is 5 h2o jvms.\n\nI guess to ease the transition, I could leave the H2O_PORT_OFFSET as the api to build_cloud(), and have another python script look at the current ho2 IP and EXECUTOR_NUMBER env variable from jenkins\n\nNotes:\nRight now, assuming the subnet octet range from a group is 160-180 or 181-190 works. 164 is an oddball case (out of the ten range for it\'s group)\n\nI guess I could just put a list of IPs for the jenkins groups that exist, and find the group your in, and then get a "group index" from that list. That\'s robust and easily maintainable.\n\nThis algorithm keeps the total port range in use = (max # of executors per jenkins master or slave) * PORTS_PER_SLOT * (# of machines in a group)\nUsing 2 executors per machine is nice. 4 is about the max that works well with h2o. so 4 * 10 * 10 = 400 ports\nthat would be 54340 thru 54721\n\nNICE POSSIBILITES: If we know that ubuntu or other services need to reserve ports that are in our range, we can put in mappings to other ports for those values, or shift the port range or whatever...i.e. we can adjust the algorithm in one place. If the 54340 base is not good, that\'s set in h2o.py..currently tests don\'t modify base_port (except for some cloud tests we don\'t run in jenkins, that do more than 5 jvms on a single machine)\n\nI suppose the tool could output the exact port to use, rather than an offset to h2o.py\'s default.  Maybe initially will output both, so h2o.py can migrate\ni.e. environment variables H2O_PORT_OFFSET and H2O_PORT (= 5321 + H2O_PORT_OFFSET)\n\nUPDATE: To allow for dispatching h2o to any machine in any jenkins group, we can have just one group list that has all possible machines. Makes the used port range twice as big (800) but that\'s okay. It\'s like going to a 255.255.0.0 network!\n\nDetail:\nJenkins has global environment variables\n\nThis one is useful\nEXECUTOR_NUMBER    The unique number that identifies the current executor (among executors of the same machine) that\'s carrying out this build. This is the number you see in the "build executor status", except that the number starts from 0, not 1.\n\nNow each slave machine can have multiple executors, in addition to the master.\n\nSo since in a grand scheme, we don\'t know who\'s creating h2o.jars on target machines, from which machine, (jenkins master or slave)...\nit means we want a global h2o port allocation (assuming that scraping an h2o port from OS allocation is ugly)\n\nI have cases on 164 jenkins that send the python job to jenkins slave 174, which dispatches h2o jars to 175-180, Or dispatch to YARN on hadoop clusters, but we don\'t care about ports there, we get told the ip/port by the h2odriver.\n\nSince the pool of machines in a group is fixed, we have the EXECUTOR_NUMBER which is the parallelism per machine (jenkins master or slave), and we\n\nWill give a unique offset to 54340\nWe can call it a "PORT_SLOT" and pass it as a environment variable like the current "export H2O_PORT_OFFSET=40"\nthat the build_cloud() uses to offset the default base_port. I suppose PORTS_PER_SLOT can be fixed in build_cloud() so it\'s the same for all jobs (so jobs don\'t step over each other.\n'
