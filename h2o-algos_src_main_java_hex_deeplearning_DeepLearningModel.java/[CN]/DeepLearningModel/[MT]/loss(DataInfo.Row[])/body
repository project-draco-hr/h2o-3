{
  double loss=0;
  Neurons[] neurons=DeepLearningTask.makeNeuronsForTraining(model_info());
  final double prefactor=_parms._distribution == Distribution.Family.laplace || _parms._distribution == Distribution.Family.quantile ? 1 : 0.5;
  long seed=-1;
  double[] responses=new double[myRows.length];
  double[] offsets=new double[myRows.length];
  for (int mb=0; mb < myRows.length; ++mb) {
    DataInfo.Row myRow=myRows[mb];
    if (myRow == null)     continue;
    ((Neurons.Input)neurons[0]).setInput(seed,myRow.numIds,myRow.numVals,myRow.nBins,myRow.binIds,mb);
    responses[mb]=myRow.response(0);
    offsets[mb]=myRow.offset;
    for (int i=0; i < neurons.length - 1; ++i) {
      Storage.DenseVector e=neurons[i]._e == null ? null : neurons[i]._e[mb];
      if (e == null)       continue;
      assert(ArrayUtils.sum(e.raw()) == 0);
    }
  }
  DeepLearningTask.fpropMiniBatch(seed,neurons,model_info(),null,false,responses,offsets,myRows.length);
  for (int mb=0; mb < myRows.length; ++mb) {
    DataInfo.Row myRow=myRows[mb];
    for (int i=0; i < neurons.length - 1; ++i) {
      Storage.DenseVector e=neurons[i]._e == null ? null : neurons[i]._e[mb];
      if (e == null)       continue;
      assert(ArrayUtils.sum(e.raw()) == 0);
    }
    if (get_params()._loss == DeepLearningParameters.Loss.CrossEntropy) {
      if (_parms._balance_classes)       throw H2O.unimpl();
      int actual=(int)myRow.response[0];
      double pred=neurons[neurons.length - 1]._a[mb].get(actual);
      loss+=-Math.log(Math.max(1e-15,pred));
    }
 else {
      if (model_info.get_params()._autoencoder)       throw H2O.unimpl();
      double pred=neurons[neurons.length - 1]._a[mb].get(0);
      double actual=myRow.response[0];
      Distribution dist=new Distribution(model_info.get_params());
      pred=dist.linkInv(pred);
      loss+=prefactor * dist.deviance(1,actual,pred);
    }
    for (int i=0; i < _parms._hidden.length + 1; ++i) {
      if (neurons[i]._w == null)       continue;
      for (int row=0; row < neurons[i]._w.rows(); ++row) {
        for (int col=0; col < neurons[i]._w.cols(); ++col) {
          loss+=_parms._l1 * Math.abs(neurons[i]._w.get(row,col));
          loss+=0.5 * _parms._l2 * Math.pow(neurons[i]._w.get(row,col),2);
        }
      }
      for (int row=0; row < neurons[i]._b.size(); ++row) {
        loss+=_parms._l1 * Math.abs(neurons[i]._b.get(row));
        loss+=0.5 * _parms._l2 * Math.pow(neurons[i]._b.get(row),2);
      }
    }
  }
  return loss;
}
