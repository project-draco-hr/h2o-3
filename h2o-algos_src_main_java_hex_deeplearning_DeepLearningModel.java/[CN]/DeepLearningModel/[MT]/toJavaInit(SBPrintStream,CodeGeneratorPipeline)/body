{
  sb=super.toJavaInit(sb,fileCtx);
  final String mname=JCodeGen.toJavaId(_key.toString());
  final Neurons[] neurons=DeepLearningTask.makeNeuronsForTesting(model_info());
  final DeepLearningParameters p=model_info.get_params();
  sb.ip("public boolean isSupervised() { return " + isSupervised() + "; }").nl();
  sb.ip("public int nfeatures() { return " + _output.nfeatures() + "; }").nl();
  sb.ip("public int nclasses() { return " + (p._autoencoder ? neurons[neurons.length - 1].units : _output.nclasses()) + "; }").nl();
  if (model_info().data_info()._nums > 0) {
    sb.i(0).p("// Thread-local storage for input neuron activation values.").nl();
    sb.i(0).p("final double[] NUMS = new double[" + model_info().data_info()._nums + "];").nl();
    JCodeGen.toClassWithArray(sb,"static","NORMMUL",model_info().data_info()._normMul);
    JCodeGen.toClassWithArray(sb,"static","NORMSUB",model_info().data_info()._normSub);
  }
  if (model_info().data_info()._cats > 0) {
    JCodeGen.toStaticVar(sb,"CATS",new int[model_info().data_info()._cats],"Workspace for storing categorical input variables.");
  }
  JCodeGen.toStaticVar(sb,"CATOFFSETS",model_info().data_info()._catOffsets,"Workspace for categorical offsets.");
  if (model_info().data_info()._normRespMul != null) {
    JCodeGen.toStaticVar(sb,"NORMRESPMUL",model_info().data_info()._normRespMul,"Standardization/Normalization scaling factor for response.");
    JCodeGen.toStaticVar(sb,"NORMRESPSUB",model_info().data_info()._normRespSub,"Standardization/Normalization offset for response.");
  }
  if (p._hidden_dropout_ratios != null) {
    JCodeGen.toStaticVar(sb,"HIDDEN_DROPOUT_RATIOS",p._hidden_dropout_ratios,"Hidden layer dropout ratios.");
  }
  final int[] layers=new int[neurons.length];
  for (int i=0; i < neurons.length; ++i)   layers[i]=neurons[i].units;
  JCodeGen.toStaticVar(sb,"NEURONS",layers,"Number of neurons for each layer.");
  if (get_params()._autoencoder) {
    sb.i(1).p("public int getPredsSize() { return " + model_info.units[model_info.units.length - 1] + "; }").nl();
    sb.i(1).p("public boolean isAutoEncoder() { return true; }").nl();
    sb.i(1).p("public String getHeader() { return \"" + getHeader() + "\"; }").nl();
  }
  sb.i(1).p("// Thread-local storage for neuron activation values.").nl();
  sb.i(1).p("final double[][] ACTIVATION = new double[][] {").nl();
  for (int i=0; i < neurons.length; i++) {
    String colInfoClazz=mname + "_Activation_" + i;
    sb.i(2).p("/* ").p(neurons[i].getClass().getSimpleName()).p(" */ ");
    sb.p(colInfoClazz).p(".VALUES");
    if (i != neurons.length - 1)     sb.p(',');
    sb.nl();
  }
  sb.i(1).p("};").nl();
  fileCtx.add(new CodeGenerator(){
    @Override public void generate(    JCodeSB out){
      for (int i=0; i < neurons.length; i++) {
        String colInfoClazz=mname + "_Activation_" + i;
        out.i().p("// Neuron activation values for ").p(neurons[i].getClass().getSimpleName()).p(" layer").nl();
        JCodeGen.toClassWithArray(out,null,colInfoClazz,new double[layers[i]]);
      }
    }
  }
);
  sb.i(1).p("// Neuron bias values.").nl();
  sb.i(1).p("public static final double[][] BIAS = new double[][] {").nl();
  for (int i=0; i < neurons.length; i++) {
    String colInfoClazz=mname + "_Bias_" + i;
    sb.i(2).p("/* ").p(neurons[i].getClass().getSimpleName()).p(" */ ");
    sb.p(colInfoClazz).p(".VALUES");
    if (i != neurons.length - 1)     sb.p(',');
    sb.nl();
  }
  sb.i(1).p("};").nl();
  fileCtx.add(new CodeGenerator(){
    @Override public void generate(    JCodeSB out){
      for (int i=0; i < neurons.length; i++) {
        String colInfoClazz=mname + "_Bias_" + i;
        out.i().p("// Neuron bias values for ").p(neurons[i].getClass().getSimpleName()).p(" layer").nl();
        double[] bias=i == 0 ? null : new double[model_info().get_biases(i - 1).size()];
        if (i > 0) {
          for (int j=0; j < bias.length; ++j)           bias[j]=model_info().get_biases(i - 1).get(j);
        }
        JCodeGen.toClassWithArray(out,null,colInfoClazz,bias);
      }
    }
  }
);
  sb.i(1).p("// Connecting weights between neurons.").nl();
  sb.i(1).p("public static final float[][] WEIGHT = new float[][] {").nl();
  for (int i=0; i < neurons.length; i++) {
    String colInfoClazz=mname + "_Weight_" + i;
    sb.i(2).p("/* ").p(neurons[i].getClass().getSimpleName()).p(" */ ");
    sb.p(colInfoClazz).p(".VALUES");
    if (i != neurons.length - 1)     sb.p(',');
    sb.nl();
  }
  sb.i(1).p("};").nl();
  fileCtx.add(new CodeGenerator(){
    @Override public void generate(    JCodeSB out){
      for (int i=0; i < neurons.length; i++) {
        String colInfoClazz=mname + "_Weight_" + i;
        if (i > 0) {
          out.i().p("// Neuron weights connecting ").p(neurons[i - 1].getClass().getSimpleName()).p(" and ").p(neurons[i].getClass().getSimpleName()).p(" layer").nl();
        }
        float[] weights=i == 0 ? null : new float[model_info().get_weights(i - 1).rows() * model_info().get_weights(i - 1).cols()];
        if (i > 0) {
          final int rows=model_info().get_weights(i - 1).rows();
          final int cols=model_info().get_weights(i - 1).cols();
          for (int j=0; j < rows; ++j)           for (int k=0; k < cols; ++k)           weights[j * cols + k]=model_info().get_weights(i - 1).get(j,k);
        }
        JCodeGen.toClassWithArray(out,null,colInfoClazz,weights);
      }
    }
  }
);
  return sb;
}
