{
  sb=super.toJavaInit(sb,fileContextSB);
  String mname=JCodeGen.toJavaId(_key.toString());
  Neurons[] neurons=DeepLearningTask.makeNeuronsForTesting(model_info());
  final DeepLearningParameters p=model_info.get_params();
  sb.ip("public boolean isSupervised() { return " + isSupervised() + "; }").nl();
  sb.ip("public int nfeatures() { return " + _output.nfeatures() + "; }").nl();
  sb.ip("public int nclasses() { return " + (p._autoencoder ? neurons[neurons.length - 1].units : _output.nclasses()) + "; }").nl();
  if (model_info().data_info()._nums > 0) {
    JCodeGen.toStaticVar(sb,"NUMS",new double[model_info().data_info()._nums],"Workspace for storing numerical input variables.");
    JCodeGen.toStaticVar(sb,"NORMMUL",model_info().data_info()._normMul,"Standardization/Normalization scaling factor for numerical variables.");
    JCodeGen.toStaticVar(sb,"NORMSUB",model_info().data_info()._normSub,"Standardization/Normalization offset for numerical variables.");
  }
  if (model_info().data_info()._cats > 0) {
    JCodeGen.toStaticVar(sb,"CATS",new int[model_info().data_info()._cats],"Workspace for storing categorical input variables.");
  }
  JCodeGen.toStaticVar(sb,"CATOFFSETS",model_info().data_info()._catOffsets,"Workspace for categorical offsets.");
  if (model_info().data_info()._normRespMul != null) {
    JCodeGen.toStaticVar(sb,"NORMRESPMUL",model_info().data_info()._normRespMul,"Standardization/Normalization scaling factor for response.");
    JCodeGen.toStaticVar(sb,"NORMRESPSUB",model_info().data_info()._normRespSub,"Standardization/Normalization offset for response.");
  }
  if (p._hidden_dropout_ratios != null) {
    JCodeGen.toStaticVar(sb,"HIDDEN_DROPOUT_RATIOS",p._hidden_dropout_ratios,"Hidden layer dropout ratios.");
  }
  int[] layers=new int[neurons.length];
  for (int i=0; i < neurons.length; ++i)   layers[i]=neurons[i].units;
  JCodeGen.toStaticVar(sb,"NEURONS",layers,"Number of neurons for each layer.");
  if (get_params()._autoencoder) {
    sb.i(1).p("public int getPredsSize() { return " + model_info.units[model_info.units.length - 1] + "; }").nl();
    sb.i(1).p("public boolean isAutoEncoder() { return true; }").nl();
    sb.i(1).p("public String getHeader() { return \"" + getHeader() + "\"; }").nl();
  }
  sb.i(1).p("// Storage for neuron activation values.").nl();
  sb.i(1).p("public static final float[][] ACTIVATION = new float[][] {").nl();
  for (int i=0; i < neurons.length; i++) {
    String colInfoClazz=mname + "_Activation_" + i;
    sb.i(2).p("/* ").p(neurons[i].getClass().getSimpleName()).p(" */ ");
    sb.p(colInfoClazz).p(".VALUES");
    if (i != neurons.length - 1)     sb.p(',');
    sb.nl();
    fileContextSB.i().p("// Neuron activation values for ").p(neurons[i].getClass().getSimpleName()).p(" layer").nl();
    JCodeGen.toClassWithArray(fileContextSB,null,colInfoClazz,new float[layers[i]]);
  }
  sb.i(1).p("};").nl();
  sb.i(1).p("// Neuron bias values.").nl();
  sb.i(1).p("public static final float[][] BIAS = new float[][] {").nl();
  for (int i=0; i < neurons.length; i++) {
    String colInfoClazz=mname + "_Bias_" + i;
    sb.i(2).p("/* ").p(neurons[i].getClass().getSimpleName()).p(" */ ");
    sb.p(colInfoClazz).p(".VALUES");
    if (i != neurons.length - 1)     sb.p(',');
    sb.nl();
    fileContextSB.i().p("// Neuron bias values for ").p(neurons[i].getClass().getSimpleName()).p(" layer").nl();
    float[] bias=i == 0 ? null : new float[model_info().get_biases(i - 1).size()];
    if (i > 0) {
      for (int j=0; j < bias.length; ++j)       bias[j]=model_info().get_biases(i - 1).get(j);
    }
    JCodeGen.toClassWithArray(fileContextSB,null,colInfoClazz,bias);
  }
  sb.i(1).p("};").nl();
  sb.i(1).p("// Connecting weights between neurons.").nl();
  sb.i(1).p("public static final float[][] WEIGHT = new float[][] {").nl();
  for (int i=0; i < neurons.length; i++) {
    String colInfoClazz=mname + "_Weight_" + i;
    sb.i(2).p("/* ").p(neurons[i].getClass().getSimpleName()).p(" */ ");
    sb.p(colInfoClazz).p(".VALUES");
    if (i != neurons.length - 1)     sb.p(',');
    sb.nl();
    if (i > 0) {
      fileContextSB.i().p("// Neuron weights connecting ").p(neurons[i - 1].getClass().getSimpleName()).p(" and ").p(neurons[i].getClass().getSimpleName()).p(" layer").nl();
    }
    float[] weights=i == 0 ? null : new float[model_info().get_weights(i - 1).rows() * model_info().get_weights(i - 1).cols()];
    if (i > 0) {
      final int rows=model_info().get_weights(i - 1).rows();
      final int cols=model_info().get_weights(i - 1).cols();
      for (int j=0; j < rows; ++j)       for (int k=0; k < cols; ++k)       weights[j * cols + k]=model_info().get_weights(i - 1).get(j,k);
    }
    JCodeGen.toClassWithArray(fileContextSB,null,colInfoClazz,weights);
  }
  sb.i(1).p("};").nl();
  return sb;
}
