{
  final long now=System.currentTimeMillis();
  final double time_since_last_iter=now - _timeLastIterationEnter;
  Log.info("doScoring. previous: _timeLasIterationEnter: " + _timeLastIterationEnter);
  Log.info("adding to total_run_time: " + total_run_time + "+= "+ time_since_last_iter+ " => "+ (total_run_time + time_since_last_iter));
  total_run_time+=time_since_last_iter;
  _timeLastIterationEnter=now;
  epoch_counter=(double)model_info().get_processed_total() / training_rows;
  boolean keep_running;
  if (H2O.CLOUD.size() > 1 && get_params()._train_samples_per_iteration == -2 && iteration > 1) {
    Log.info("Auto-tuning train_samples_per_iteration.");
    if (time_for_communication_us > 1e4) {
      Log.info("  Time taken for communication: " + PrettyPrint.usecs((long)time_for_communication_us));
      Log.info("  Time taken for Map/Reduce iteration: " + PrettyPrint.msecs((long)time_since_last_iter,true));
      final double comm_to_work_ratio=(time_for_communication_us * 1e-3) / time_since_last_iter;
      Log.info("  Ratio of network communication to computation: " + String.format("%.5f",comm_to_work_ratio));
      Log.info("  target_comm_to_work: " + get_params()._target_ratio_comm_to_comp);
      Log.info("Old value of train_samples_per_iteration: " + actual_train_samples_per_iteration);
      double correction=get_params()._target_ratio_comm_to_comp / comm_to_work_ratio;
      correction=Math.max(0.5,Math.min(2,correction));
      if (Math.abs(correction) < 0.8 || Math.abs(correction) > 1.2) {
        actual_train_samples_per_iteration/=correction;
        actual_train_samples_per_iteration=Math.max(1,actual_train_samples_per_iteration);
        Log.info("New value of train_samples_per_iteration: " + actual_train_samples_per_iteration);
      }
 else {
        Log.info("Keeping value of train_samples_per_iteration the same (would deviate too little from previous value): " + actual_train_samples_per_iteration);
      }
    }
 else {
      Log.info("Communication is faster than 10 ms. Not modifying train_samples_per_iteration: " + actual_train_samples_per_iteration);
    }
  }
  keep_running=(epoch_counter < get_params()._epochs) && !stopped_early;
  final long sinceLastScore=now - _timeLastScoreStart;
  if (!keep_running || (sinceLastScore > get_params()._score_interval * 1000 && (double)(_timeLastScoreEnd - _timeLastScoreStart) / sinceLastScore < get_params()._score_duty_cycle)) {
    if (progressKey != null) {
      new Job.ProgressUpdate("Scoring on " + ftrain.numRows() + " training samples"+ (ftest != null ? (", " + ftest.numRows() + " validation samples") : "")).fork(progressKey);
    }
    final boolean printme=!get_params()._quiet_mode;
    _timeLastScoreStart=System.currentTimeMillis();
    Log.info("doScoring. _timeLastScoreStart: " + _timeLastScoreStart);
    model_info().computeStats();
    DeepLearningScoring err=new DeepLearningScoring();
    err.time_stamp=_timeLastScoreStart;
    Log.info("setting err.training_time_ms to " + total_run_time);
    err.training_time_ms=total_run_time;
    err.epoch_counter=epoch_counter;
    err.iterations=iterations;
    err.training_samples=(double)model_info().get_processed_total();
    err.validation=ftest != null;
    err.score_training_samples=ftrain.numRows();
    err.classification=_output.isClassifier();
    if (get_params()._autoencoder) {
      if (printme)       Log.info("Scoring the auto-encoder.");
{
        final Frame mse_frame=scoreAutoEncoder(ftrain,Key.make(),false);
        mse_frame.delete();
        ModelMetrics mtrain=ModelMetrics.getFromDKV(this,ftrain);
        _output._training_metrics=mtrain;
        err.scored_train=new ScoreKeeper(mtrain);
      }
      if (ftest != null) {
        final Frame mse_frame=scoreAutoEncoder(ftest,Key.make(),false);
        mse_frame.delete();
        ModelMetrics mtest=ModelMetrics.getFromDKV(this,ftest);
        _output._validation_metrics=mtest;
        err.scored_valid=new ScoreKeeper(mtest);
      }
    }
 else {
      if (printme)       Log.info("Scoring the model.");
      final String m=model_info().toString();
      if (m.length() > 0)       Log.info(m);
      final Frame trainPredict=score(ftrain);
      trainPredict.delete();
      hex.ModelMetrics mtrain=ModelMetrics.getFromDKV(this,ftrain);
      _output._training_metrics=mtrain;
      err.scored_train=new ScoreKeeper(mtrain);
      hex.ModelMetrics mtest;
      hex.ModelMetricsSupervised mm1=(ModelMetricsSupervised)ModelMetrics.getFromDKV(this,ftrain);
      if (mm1 instanceof ModelMetricsBinomial) {
        ModelMetricsBinomial mm=(ModelMetricsBinomial)(mm1);
        err.training_AUC=mm._auc;
      }
      if (ftrain.numRows() != training_rows) {
        _output._training_metrics._description="Metrics reported on temporary training frame with " + ftrain.numRows() + " samples";
      }
 else       if (ftrain._key != null && ftrain._key.toString().contains("chunks")) {
        _output._training_metrics._description="Metrics reported on temporary (load-balanced) training frame";
      }
 else {
        _output._training_metrics._description="Metrics reported on full training frame";
      }
      if (ftest != null) {
        Frame validPred=score(ftest);
        validPred.delete();
        mtest=ModelMetrics.getFromDKV(this,ftest);
        _output._validation_metrics=mtest;
        err.scored_valid=new ScoreKeeper(mtest);
        if (mtest != null) {
          if (mtest instanceof ModelMetricsBinomial) {
            ModelMetricsBinomial mm=(ModelMetricsBinomial)mtest;
            err.validation_AUC=mm._auc;
          }
          if (ftest.numRows() != validation_rows) {
            _output._validation_metrics._description="Metrics reported on temporary validation frame with " + ftest.numRows() + " samples";
            if (get_params()._score_validation_sampling == DeepLearningParameters.ClassSamplingMethod.Stratified) {
              _output._validation_metrics._description+=" (stratified sampling)";
            }
          }
 else           if (ftest._key != null && ftest._key.toString().contains("chunks")) {
            _output._validation_metrics._description="Metrics reported on temporary (load-balanced) validation frame";
          }
 else {
            _output._validation_metrics._description="Metrics reported on full validation frame";
          }
        }
      }
    }
    if (get_params()._variable_importances) {
      if (!get_params()._quiet_mode)       Log.info("Computing variable importances.");
      final float[] vi=model_info().computeVariableImportances();
      err.variable_importances=new VarImp(vi,Arrays.copyOfRange(model_info().data_info().coefNames(),0,vi.length));
    }
    _timeLastScoreEnd=System.currentTimeMillis();
    Log.info("_timeLastScoreEnd: " + _timeLastScoreEnd);
    err.scoring_time=_timeLastScoreEnd - _timeLastScoreStart;
    Log.info("scoring_time:: " + err.scoring_time);
    err.training_time_ms+=err.scoring_time;
    Log.info("now training_time_ms: " + err.training_time_ms);
    total_scoring_time+=err.scoring_time;
    Log.info("now total_scoring_time: " + total_scoring_time);
    if (scoringInfo == null) {
      scoringInfo=new DeepLearningScoring[]{err};
    }
 else {
      DeepLearningScoring[] err2=new DeepLearningScoring[scoringInfo.length + 1];
      System.arraycopy(scoringInfo,0,err2,0,scoringInfo.length);
      err2[err2.length - 1]=err;
      scoringInfo=err2;
    }
    _output.errors=last_scored();
    makeWeightsBiases(_key);
    water.util.Timer t=new Timer();
    if (_output.weights != null && _output.biases != null) {
      for (int i=0; i < _output.weights.length; ++i) {
        Frame f=model_info.get_weights(i).toFrame(_output.weights[i]);
        if (i == 0) {
          f._names=model_info.data_info.coefNames();
          DKV.put(f);
        }
      }
      for (int i=0; i < _output.biases.length; ++i) {
        model_info.get_biases(i).toFrame(_output.biases[i]);
      }
      if (!_parms._quiet_mode)       Log.info("Writing weights and biases to Frames took " + t.time() / 1000. + " seconds.");
    }
    _output._scoring_history=createScoringHistoryTable(scoringInfo);
    _output._variable_importances=calcVarImp(last_scored().variable_importances);
    _output._model_summary=model_info.createSummaryTable();
    if (!finalScoring) {
      if (actual_best_model_key != null && get_params()._overwrite_with_best_model && ((DKV.get(actual_best_model_key) != null && (loss() < DKV.get(actual_best_model_key).<DeepLearningModel>get().loss() || !Arrays.equals(model_info().units,DKV.get(actual_best_model_key).<DeepLearningModel>get().model_info().units))) || (DKV.get(actual_best_model_key) == null && loss() < _bestLoss))) {
        _bestLoss=loss();
        putMeAsBestModel(actual_best_model_key);
      }
      if (keep_running && printme)       Log.info(toString());
      if ((_output.isClassifier() && last_scored().scored_train._classError <= get_params()._classification_stop) || (!_output.isClassifier() && last_scored().scored_train._mse <= get_params()._regression_stop)) {
        Log.info("Achieved requested predictive accuracy on the training data. Model building completed.");
        stopped_early=true;
      }
      if (ScoreKeeper.earlyStopping(scoreKeepers(),get_params()._stopping_rounds,_output.isClassifier(),get_params()._stopping_metric,get_params()._stopping_tolerance)) {
        Log.info("Convergence detected based on simple moving average of the loss function for the past " + get_params()._stopping_rounds + " scoring events. Model building completed.");
        stopped_early=true;
      }
      if (printme)       Log.info("Time taken for scoring and diagnostics: " + PrettyPrint.msecs(err.scoring_time,true));
    }
  }
  if (stopped_early) {
    ((Job)DKV.getGet(job_key)).update((long)(_parms._epochs * training_rows));
    update(job_key);
    return false;
  }
  progressUpdate(progressKey,job_key,keep_running);
  update(job_key);
  return keep_running;
}
