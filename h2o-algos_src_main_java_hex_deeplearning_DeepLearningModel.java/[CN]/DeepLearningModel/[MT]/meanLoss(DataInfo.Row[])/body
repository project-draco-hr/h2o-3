{
  double loss=0;
  Neurons[] neurons=DeepLearningTask.makeNeuronsForTraining(model_info());
  long seed=-1;
  double[] responses=new double[myRows.length];
  double[] offsets=new double[myRows.length];
  int n=0;
  for (int mb=0; mb < myRows.length; ++mb) {
    DataInfo.Row myRow=myRows[mb];
    if (myRow == null)     continue;
    n++;
    ((Neurons.Input)neurons[0]).setInput(seed,myRow.numIds,myRow.numVals,myRow.nBins,myRow.binIds,mb);
    responses[mb]=myRow.response(0);
    offsets[mb]=myRow.offset;
    for (int i=0; i < neurons.length - 1; ++i) {
      Storage.DenseVector e=neurons[i]._e == null ? null : neurons[i]._e[mb];
      if (e == null)       continue;
      assert(ArrayUtils.sum(e.raw()) == 0);
    }
  }
  DeepLearningTask.fpropMiniBatch(seed,neurons,model_info(),null,false,responses,offsets,myRows.length);
  for (int mb=0; mb < myRows.length; ++mb) {
    DataInfo.Row myRow=myRows[mb];
    if (myRow == null)     continue;
    for (int i=0; i < neurons.length - 1; ++i) {
      Storage.DenseVector e=neurons[i]._e == null ? null : neurons[i]._e[mb];
      if (e == null)       continue;
      assert(ArrayUtils.sum(e.raw()) == 0);
    }
    if (get_params()._loss == CrossEntropy) {
      if (get_params()._balance_classes)       throw H2O.unimpl();
      int actual=(int)myRow.response[0];
      double pred=neurons[neurons.length - 1]._a[mb].get(actual);
      loss+=-Math.log(Math.max(1e-15,pred));
    }
 else {
      if (model_info.get_params()._autoencoder)       throw H2O.unimpl();
      double pred=neurons[neurons.length - 1]._a[mb].get(0);
      double actual=myRow.response[0];
      pred=_dist.linkInv(pred);
      loss+=_dist.deviance(1,actual,pred);
    }
    for (int i=0; i <= get_params()._hidden.length + 1; ++i) {
      if (neurons[i]._w != null) {
        for (int row=0; row < neurons[i]._w.rows(); ++row) {
          for (int col=0; col < neurons[i]._w.cols(); ++col) {
            loss+=get_params()._l1 * Math.abs(neurons[i]._w.get(row,col));
            loss+=0.5 * get_params()._l2 * Math.pow(neurons[i]._w.get(row,col),2);
          }
        }
      }
      if (neurons[i]._b != null) {
        for (int row=0; row < neurons[i]._b.size(); ++row) {
          loss+=get_params()._l1 * Math.abs(neurons[i]._b.get(row));
          loss+=0.5 * get_params()._l2 * Math.pow(neurons[i]._b.get(row),2);
        }
      }
    }
  }
  return n > 0 ? loss / n : loss;
}
