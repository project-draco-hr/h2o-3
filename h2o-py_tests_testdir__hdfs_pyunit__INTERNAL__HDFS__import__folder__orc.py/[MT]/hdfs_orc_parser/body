def hdfs_orc_parser():
    hadoop_namenode_is_accessible = pyunit_utils.hadoop_namenode_is_accessible()
    if hadoop_namenode_is_accessible:
        hdfs_name_node = pyunit_utils.hadoop_namenode()
        if pyunit_utils.cannaryHDFSTest(hdfs_name_node, '/datasets/orc_parser/orc/orc_split_elim.orc'):
            print('Your hive-exec version is too old.  Orc parser test {0} is skipped.'.format('pyunit_INTERNAL_HDFS_import_folder_orc.py'))
            pass
        else:
            tol_time = 200
            tol_numeric = 1e-05
            numElements2Compare = 0
            hdfs_csv_file1 = '/datasets/orc_parser/csv/balunbal.csv'
            url_csv1 = 'hdfs://{0}{1}'.format(hdfs_name_node, hdfs_csv_file1)
            multi_file_csv1 = h2o.import_file(url_csv1)
            hdfs_csv_file2 = '/datasets/orc_parser/csv/unbalbal.csv'
            url_csv2 = 'hdfs://{0}{1}'.format(hdfs_name_node, hdfs_csv_file2)
            multi_file_csv2 = h2o.import_file(url_csv2)
            hdfs_orc_file = '/datasets/orc_parser/synthetic_perfect_separation_orc'
            url_orc = 'hdfs://{0}{1}'.format(hdfs_name_node, hdfs_orc_file)
            multi_file_orc = h2o.import_file(url_orc)
            try:
                assert pyunit_utils.compare_frames(multi_file_orc, multi_file_csv1, numElements2Compare, tol_time=tol_time, tol_numeric=tol_numeric, strict=True), 'H2O frame parsed from multiple orc and single orc files are different!'
            except:
                assert pyunit_utils.compare_frames(multi_file_orc, multi_file_csv2, numElements2Compare, tol_time=tol_time, tol_numeric=tol_numeric, strict=True), 'H2O frame parsed from multiple orc and single orc files are different!'
    else:
        raise EnvironmentError
