{
  if (_model._output._ntrees == 0)   return;
  int model_mem_size=0;
  int trees_so_far=_model._output._ntrees;
  for (int i=0; i < trees_so_far; ++i) {
    Key<CompressedTree>[] per_class=_model._output._treeKeys[i];
    for (int j=0; j < per_class.length; ++j) {
      if (per_class[j] == null)       continue;
      model_mem_size+=DKV.get(per_class[j]).memOrLoad().length;
    }
  }
  double avg_tree_mem_size=(double)model_mem_size / trees_so_far;
  Log.debug("Average tree size (for all classes): " + PrettyPrint.bytes((long)avg_tree_mem_size));
  long mem_per_node=Long.MAX_VALUE;
  for (int i=0; i < H2O.CLOUD.size(); ++i) {
    mem_per_node=Math.min(H2O.CLOUD._memary[i]._heartbeat.get_max_mem(),mem_per_node);
  }
  if (_parms._ntrees * avg_tree_mem_size > H2O.CLOUD.size() * mem_per_node) {
    String msg="The tree model will not fit in this cluster's memory (" + PrettyPrint.bytes((long)avg_tree_mem_size) + " per tree x "+ _parms._ntrees+ " > "+ PrettyPrint.bytes(H2O.CLOUD.size() * mem_per_node)+ ") - try decreasing ntrees and/or max_depth or increasing min_rows!";
    error("_ntrees",msg);
    throw new IllegalArgumentException(msg);
  }
}
