def __init__(self, k=None, max_iterations=None, transform=None, seed=None, ignore_const_cols=None, loss=None, multi_loss=None, loss_by_col=None, loss_by_col_idx=None, regularization_x=None, regularization_y=None, gamma_x=None, gamma_y=None, init_step_size=None, min_step_size=None, init=None, svd_method=None, user_x=None, user_y=None, recover_svd=None):
    '\n    Builds a generalized low rank model of a H2O dataset.\n\n    Parameters\n    ----------\n      k : int\n        The rank of the resulting decomposition. This must be between 1 and the number of\n        columns in the training frame inclusive.\n      max_iterations : int\n        The maximum number of iterations to run the optimization loop. Each iteration\n        consists of an update of the X matrix, followed by an update of the Y matrix.\n      transform : str\n        A character string that indicates how the training data should be transformed\n        before running GLRM. Possible values are\n            "NONE": for no transformation,\n            "DEMEAN": for subtracting the mean of each column,\n            "DESCALE": for dividing by the standard deviation of each column,\n            "STANDARDIZE": for demeaning and descaling, and\n            "NORMALIZE": for demeaning and dividing each column by its range (max - min).\n      seed : int, optional\n        Random seed used to initialize the X and Y matrices.\n      ignore_const_cols : bool, optional\n        A logical value indicating whether to ignore constant columns in the training frame.\n        A column is constant if all of its non-missing values are the same value.\n      loss : str\n        A character string indicating the default loss function for numeric columns.\n        Possible values are\n            "Quadratic" (default),\n            "Absolute",\n            "Huber",\n            "Poisson",\n            "Hinge", and\n            "Logistic".\n      multi_loss : str\n        A character string indicating the default loss function for enum columns. Possible\n        values are "Categorical" and "Ordinal".\n      loss_by_col : str, optional\n        A list of strings indicating the loss function for specific columns by\n        corresponding index in loss_by_col_idx. Will override loss for numeric columns\n        and multi_loss for enum columns.\n      loss_by_col_idx : str, optional\n        A list of column indices to which the corresponding loss functions in loss_by_col\n        are assigned. Must be zero indexed.\n      regularization_x : str\n        A character string indicating the regularization function for the X matrix.\n        Possible values are\n            "None" (default),\n            "Quadratic",\n            "L2",\n            "L1",\n            "NonNegative",\n            "OneSparse",\n            "UnitOneSparse", and\n            "Simplex".\n      regularization_y : str\n        A character string indicating the regularization function for the Y matrix.\n        Possible values are\n            "None" (default),\n            "Quadratic",\n            "L2",\n            "L1",\n            "NonNegative",\n            "OneSparse",\n            "UnitOneSparse", and\n            "Simplex".\n      gamma_x : float\n        The weight on the X matrix regularization term.\n      gamma_y : float\n        The weight on the Y matrix regularization term.\n      init_step_size : float\n        Initial step size. Divided by number of columns in the training frame when\n        calculating the proximal gradient update. The algorithm begins at init_step_size\n        and decreases the step size at each iteration until a termination condition is\n        reached.\n      min_step_size : float\n        Minimum step size upon which the algorithm is terminated.\n      init : str\n        A character string indicating how to select the initial X and Y matrices.\n        Possible values are\n            "Random": for initialization to a random array from the standard normal\n                      distribution,\n            "PlusPlus": for initialization using the clusters from k-means++\n                        initialization,\n            "SVD": for initialization using the first k (approximate) right singular\n                   vectors, and\n            "User": user-specified initial X and Y frames\n                    (must set user_y and user_x arguments).\n      svd_method : str\n        A character string that indicates how SVD should be calculated during\n        initialization. Possible values are\n            "GramSVD": distributed computation of the Gram matrix followed by a local\n                      SVD using the JAMA package,\n            "Power": computation of the SVD using the power iteration method,\n            "Randomized": approximate SVD by projecting onto a random subspace.\n      user_x : H2OFrame, optional\n        An H2OFrame object specifying the initial X matrix. Only used when init = "User".\n      user_y : H2OFrame, optional\n        An H2OFrame object specifying the initial Y matrix. Only used when init = "User".\n      recover_svd : bool\n        A logical value indicating whether the singular values and eigenvectors should be\n        recovered during post-processing of the generalized low rank decomposition.\n\n    Returns\n    -------\n      A new H2OGeneralizedLowRankEstimator instance.\n    '
    super(H2OGeneralizedLowRankEstimator, self).__init__()
    self._parms = locals()
    self._parms = {k: v for (k, v) in self._parms.iteritems() if (k != 'self')}
    self._parms['_rest_version'] = 99
