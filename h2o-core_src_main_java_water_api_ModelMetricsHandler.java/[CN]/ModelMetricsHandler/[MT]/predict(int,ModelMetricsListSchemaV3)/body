{
  ModelMetricsList parms=s.createAndFillImpl();
  if (null == parms._destination_key)   parms._destination_key="predictions_" + parms._model._key.toString() + "_on_"+ parms._frame._key.toString();
  Frame predictions;
  if (!s.reconstruction_error && s.deep_features_hidden_layer < 0) {
    predictions=parms._model.score(parms._frame,parms._destination_key);
  }
 else {
    if (Model.DeepFeatures.class.isAssignableFrom(parms._model.getClass())) {
      if (s.reconstruction_error) {
        if (s.deep_features_hidden_layer >= 0)         throw new H2OIllegalArgumentException("Can only compute either reconstruction error OR deep features.","");
        predictions=((Model.DeepFeatures)parms._model).scoreAutoEncoder(parms._frame);
      }
 else {
        if (s.deep_features_hidden_layer < 0)         throw new H2OIllegalArgumentException("Deep features hidden layer index must be >= 0.","");
        predictions=((Model.DeepFeatures)parms._model).scoreDeepFeatures(parms._frame,s.deep_features_hidden_layer);
      }
      predictions=new Frame(Key.make(parms._destination_key),predictions.names(),predictions.vecs());
      DKV.put(predictions._key,predictions);
    }
 else     throw new H2OIllegalArgumentException("Require a Deep Learning AutoEncoder model.","");
  }
  ModelMetricsListSchemaV3 mm=this.fetch(version,s);
  if (null == mm)   mm=new ModelMetricsListSchemaV3();
  if (null == mm.model_metrics || 0 == mm.model_metrics.length) {
    Log.warn("Score() did not return a ModelMetrics for model: " + s.model + " on frame: "+ s.frame);
  }
 else {
    mm.model_metrics[0].predictions=new FrameV2(predictions,0,100);
  }
  return mm;
}
