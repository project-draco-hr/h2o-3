def glrm(x, validation_x=None, training_frame=None, validation_frame=None, k=None, max_iterations=None, max_updates=None, transform=None, seed=None, ignore_const_cols=None, loss=None, multi_loss=None, loss_by_col=None, loss_by_col_idx=None, regularization_x=None, regularization_y=None, gamma_x=None, gamma_y=None, init_step_size=None, min_step_size=None, init=None, svd_method=None, user_y=None, user_x=None, expand_user_y=None, impute_original=None, recover_svd=None, max_runtime_secs=None):
    '\n  Builds a generalized low rank model of a H2O dataset.\n\n  Parameters\n  ----------\n\n  k : int\n    The rank of the resulting decomposition. This must be between 1 and the number of columns in the training frame inclusive.\n  max_iterations : int\n    The maximum number of iterations to run the optimization loop. Each iteration consists of an update of the X matrix, followed by an\n    update of the Y matrix.\n  max_updates : int\n    The maximum number of updates of X or Y to run. Each update consists of an update of either the X matrix or the Y matrix. For example, \n    if max_updates = 1 and max_iterations = 1, the algorithm will initialize X and Y, update X once, and terminate without updating Y.\n  transform : str\n    A character string that indicates how the training data should be transformed before running GLRM.\n    Possible values are "NONE": for no transformation, "DEMEAN": for subtracting the mean of each column, "DESCALE": for\n    dividing by the standard deviation of each column, "STANDARDIZE": for demeaning and descaling, and "NORMALIZE": for\n    demeaning and dividing each column by its range (max - min).\n  seed : int\n    (Optional) Random seed used to initialize the X and Y matrices.\n  ignore_const_cols : bool\n    (Optional) A logical value indicating whether to ignore constant columns in the training frame. A column is constant if all of its\n    non-missing values are the same value.\n  loss : str\n    A character string indicating the default loss function for numeric columns. Possible values are "Quadratic" (default), "Absolute", "Huber",\n    "Poisson", "Hinge", and "Logistic".\n  multi_loss : str\n    A character string indicating the default loss function for enum columns. Possible values are "Categorical" and "Ordinal".\n  loss_by_col : str\n    (Optional) A list of strings indicating the loss function for specific columns by corresponding index in loss_by_col_idx.\n    Will override loss for numeric columns and multi_loss for enum columns.\n  loss_by_col_idx : str\n    (Optional) A list of column indices to which the corresponding loss functions in loss_by_col are assigned. Must be zero indexed.\n  regularization_x : str\n    A character string indicating the regularization function for the X matrix. Possible values are "None" (default), "Quadratic",\n    "L2", "L1", "NonNegative", "OneSparse", "UnitOneSparse", and "Simplex".\n  regularization_y : str\n    A character string indicating the regularization function for the Y matrix. Possible values are "None" (default), "Quadratic",\n    "L2", "L1", "NonNegative", "OneSparse", "UnitOneSparse", and "Simplex".\n  gamma_x : float\n    The weight on the X matrix regularization term.\n  gamma_y : float\n    The weight on the Y matrix regularization term.\n  init_step_size : float\n    Initial step size. Divided by number of columns in the training frame when calculating the proximal gradient update. The algorithm\n    begins at init_step_size and decreases the step size at each iteration until a termination condition is reached.\n  min_step_size : float\n    Minimum step size upon which the algorithm is terminated.\n  init : str\n    A character string indicating how to select the initial X and Y matrices.\n    Possible values are "Random": for initialization to a random array from the standard normal distribution, "PlusPlus": for initialization\n    using the clusters from k-means++ initialization, "SVD": for initialization using the first k (approximate) right singular vectors, and\n    "User": user-specified initial X and Y frames (must set user_y and user_x arguments).\n  svd_method : str\n    A character string that indicates how SVD should be calculated during initialization.\n    Possible values are "GramSVD": distributed computation of the Gram matrix followed by a local SVD using the JAMA package,\n    "Power": computation of the SVD using the power iteration method, "Randomized": approximate SVD by projecting onto a random subspace.\n  user_x : H2OFrame\n    (Optional) An H2OFrame object specifying the initial X matrix. Only used when init = "User".\n  user_y : H2OFrame\n    (Optional) An H2OFrame object specifying the initial Y matrix. Only used when init = "User".\n  expand_user_y : bool\n\tA logical value indicating whether the categorical columns of the initial Y matrix should be one-hot expanded. Only used when init = "User"\n    and user_y is specified.\n  impute_original : bool\n    A logical value indicating whether to reconstruct the original training data by reversing the transformation during prediction.\n    Model metrics are calculated with respect to the original data.\n  recover_svd : bool\n    A logical value indicating whether the singular values and eigenvectors should be recovered during post-processing of the generalized\n    low rank decomposition.\n\n\n  :return: a new dim reduction model\n  '
    warnings.warn('`h2o.glrm` is deprecated. Use the estimators sub module to build an H2OGeneralizedLowRankEstimator.', category=DeprecationWarning, stacklevel=2)
    parms = {k: v for (k, v) in locals().items() if ((k in ['training_frame', 'validation_frame', 'validation_x', 'validation_y', 'offset_column', 'weights_column', 'fold_column']) or (v is not None))}
    parms['algo'] = 'glrm'
    parms['_rest_version'] = 3
    return unsupervised(parms)
