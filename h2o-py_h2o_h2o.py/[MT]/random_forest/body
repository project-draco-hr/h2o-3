def random_forest(x, y, validation_x=None, validation_y=None, training_frame=None, model_id=None, mtries=None, sample_rate=None, build_tree_one_node=None, ntrees=None, max_depth=None, min_rows=None, nbins=None, nbins_cats=None, binomial_double_trees=None, validation_frame=None, balance_classes=None, max_after_balance_size=None, seed=None, offset_column=None, weights_column=None, nfolds=None, fold_column=None, fold_assignment=None, keep_cross_validation_predictions=None, checkpoint=None):
    '\n  Build a Big Data Random Forest Model\n  Builds a Random Forest Model on an H2OFrame\n\n\n  Parameters\n  ----------\n\n  x : H2OFrame\n    An H2OFrame containing the predictors in the model.\n  y : H2OFrame\n    An H2OFrame of the response variable in the model.\n  training_frame : H2OFrame\n    (Optional) An H2OFrame. Only used to retrieve weights, offset, or nfolds columns, if they aren\'t already provided in x.\n  model_id : str\n    (Optional) The unique id assigned to the resulting model. If none is given, an id will automatically be generated.\n  mtries : int\n    Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrt{p} for classification, and p/3 for regression, \n    where p is the number of predictors.\n  sample_rate : float\n    Sample rate, from 0 to 1.0.\n  build_tree_one_node : bool\n    Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.\n  ntrees : int\n    A nonnegative integer that determines the number of trees to grow.\n  max_depth : int\n    Maximum depth to grow the tree.\n  min_rows : int\n    Minimum number of rows to assign to teminal nodes.\n  nbins : int\n    For numerical columns (real/int), build a histogram of this many bins, then split at the best point.\n  nbins_cats : int\n    For categorical columns (enum), build a histogram of this many bins, then split at the best point. Higher values can lead to more overfitting.\n  binomial_double_trees : bool\n    or binary classification: Build 2x as many trees (one per class) - can lead to higher accuracy.\n  validation_frame : H2OFrame\n     An H2OFrame object containing the variables in the model.\n  balance_classes : bool\n    logical, indicates whether or not to balance training data class counts via over/under-sampling (for imbalanced data)\n  max_after_balance_size : float\n    Maximum relative size of the training data after balancing class counts (can be less than 1.0). Ignored if balance_classes is False, which is the default behavior.\n  seed : int\n    Seed for random numbers (affects sampling) - Note: only reproducible when running single threaded\n  offset_column : H2OFrame\n    Specify the offset column.\n  weights_column : H2OFrame\n    Specify the weights column.\n  nfolds : int\n    (Optional) Number of folds for cross-validation. If nfolds >= 2, then validation must remain empty.\n  fold_column : H2OFrame\n    (Optional) Column with cross-validation fold index assignment per observation\n  fold_assignment : str\n    Cross-validation fold assignment scheme, if fold_column is not specified Must be "AUTO", "Random" or "Modulo"\n  keep_cross_validation_predictions : bool\n    Whether to keep the predictions of the cross-validation models\n\n  :return: A new classifier or regression model.\n  '
    parms = {k: v for (k, v) in locals().items() if ((k in ['training_frame', 'validation_frame', 'validation_x', 'validation_y', 'offset_column', 'weights_column', 'fold_column']) or (v is not None))}
    parms['algo'] = 'drf'
    return h2o_model_builder.supervised(parms)
