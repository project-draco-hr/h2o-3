def glm(x, y, validation_x=None, validation_y=None, training_frame=None, model_id=None, validation_frame=None, max_iterations=None, beta_epsilon=None, solver=None, standardize=None, family=None, link=None, tweedie_variance_power=None, tweedie_link_power=None, alpha=None, prior=None, lambda_search=None, nlambdas=None, lambda_min_ratio=None, beta_constraints=None, offset_column=None, weights_column=None, nfolds=None, fold_column=None, fold_assignment=None, keep_cross_validation_predictions=None, intercept=None, Lambda=None, do_future=None):
    '\n  Build a Generalized Linear Model\n  Fit a generalized linear model, specified by a response variable, a set of predictors, and a description of the error\n  distribution.\n\n  :param x: An H2OFrame containing the predictors in the model.\n  :param y: An H2OFrame of the response variable in the model.\n  :param training_frame: (Optional) An H2OFrame. Only used to retrieve weights, offset, or nfolds columns, if they aren\'t already provided in x.\n  :param model_id: (Optional) The unique id assigned to the resulting model. If none is given, an id will automatically be generated.\n  :param validation_frame: An H2OFrame object containing the variables in the model.\n  :param max_iterations: A non-negative integer specifying the maximum number of iterations.\n  :param beta_epsilon: A non-negative number specifying the magnitude of the maximum difference between the coefficient estimates from successive iterations. Defines the convergence criterion for h2o.glm.\n  :param solver: A character string specifying the solver used: IRLSM (supports more features), L_BFGS (scales better for datasets with many columns)\n  :param standardize: A logical value indicating whether the numeric predictors should be standardized to have a mean of 0 and a variance of 1 prior to training the models.\n  :param family: A character string specifying the distribution of the model:  gaussian, binomial, poisson, gamma, tweedie.\n  :param link: A character string specifying the link function. The default is the canonical link for the family.\n  The supported links for each of the family specifications are:\n          "gaussian": "identity", "log", "inverse"\n          "binomial": "logit", "log"\n          "poisson": "log", "identity"\n          "gamma": "inverse", "log", "identity"\n          "tweedie": "tweedie"\n  :param tweedie_variance_power: A numeric specifying the power for the variance function when family = "tweedie".\n  :param tweedie_link_power: A numeric specifying the power for the link function when family = "tweedie".\n  :param alpha: A numeric in [0, 1] specifying the elastic-net mixing parameter.\n  The elastic-net penalty is defined to be:\n  eqn{P(\x07lpha,\x08eta) = (1-\x07lpha)/2||\x08eta||_2^2 + \x07lpha||\x08eta||_1 = \\sum_j [(1-\x07lpha)/2 \x08eta_j^2 + \x07lpha|\x08eta_j|],\n  making alpha = 1 the lasso penalty and alpha = 0 the ridge penalty.\n  :param Lambda: A non-negative shrinkage parameter for the elastic-net, which multiplies \\eqn{P(\x07lpha,\x08eta) in the objective function. When lambda = 0, no elastic-net penalty is applied and ordinary generalized linear models are fit.\n  :param prior: (Optional) A numeric specifying the prior probability of class 1 in the response when family = "binomial". The default prior is the observational frequency of class 1.\n  :param lambda_search: A logical value indicating whether to conduct a search over the space of lambda values starting from the lambda max, given lambda is interpreted as lambda min.\n  :param nlambdas: The number of lambda values to use when lambda_search = TRUE.\n  :param lambda_min_ratio: Smallest value for lambda as a fraction of lambda.max. By default if the number of\n  observations is greater than the the number of variables then lambda_min_ratio = 0.0001; if the number of\n  observations is less than the number of variables then lambda_min_ratio = 0.01.\n  :param beta_constraints: A data.frame or H2OParsedData object with the columns ["names", "lower_bounds",\n  "upper_bounds", "beta_given"], where each row corresponds to a predictor in the GLM. "names" contains the predictor\n  names, "lower"/"upper_bounds", are the lower and upper bounds of beta, and "beta_given" is some supplied starting\n  values for the\n  :param offset_column: Specify the offset column.\n  :param weights_column: Specify the weights column.\n  :param nfolds: (Optional) Number of folds for cross-validation. If nfolds >= 2, then validation must remain empty.\n  :param fold_column: (Optional) Column with cross-validation fold index assignment per observation\n  :param fold_assignment: Cross-validation fold assignment scheme, if fold_column is not specified Must be "AUTO", "Random" or "Modulo"\n  :param keep_cross_validation_predictions: Whether to keep the predictions of the cross-validation models\n  :param intercept: Logical, include constant term (intercept) in the model\n  :return: A subclass of ModelBase is returned. The specific subclass depends on the machine learning task at hand (if\n  it\'s binomial classification, then an H2OBinomialModel is returned, if it\'s regression then a H2ORegressionModel is\n  returned). The default print-out of the models is shown, but further GLM-specifc information can be queried out of\n  the object.\n  Upon completion of the GLM, the resulting object has coefficients, normalized coefficients, residual/null deviance,\n  aic, and a host of model metrics including MSE, AUC (for logistic regression), degrees of freedom, and confusion\n  matrices.\n  '
    parms = {k.lower(): v for (k, v) in locals().items() if ((k in ['training_frame', 'validation_frame', 'validation_x', 'validation_y', 'offset_column', 'weights_column', 'fold_column']) or (v is not None))}
    parms['algo'] = 'glm'
    return h2o_model_builder.supervised(parms)
