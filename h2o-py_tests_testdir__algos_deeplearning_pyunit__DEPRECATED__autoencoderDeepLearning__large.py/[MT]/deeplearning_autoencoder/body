def deeplearning_autoencoder():
    resp = 784
    nfeatures = 20
    train_hex = h2o.upload_file(pyunit_utils.locate('bigdata/laptop/mnist/train.csv.gz'))
    train_hex[resp] = train_hex[resp].asfactor()
    test_hex = h2o.upload_file(pyunit_utils.locate('bigdata/laptop/mnist/test.csv.gz'))
    test_hex[resp] = test_hex[resp].asfactor()
    sid = train_hex[0].runif(1234)
    train_unsupervised = train_hex[(sid >= 0.5)]
    train_unsupervised.drop(resp)
    train_unsupervised.describe()
    train_supervised = train_hex[(sid < 0.5)]
    train_supervised.describe()
    ae_model = h2o.deeplearning(x=train_unsupervised[0:resp], activation='Tanh', autoencoder=True, hidden=[nfeatures], epochs=1, reproducible=True, seed=1234)
    train_supervised_features = ae_model.deepfeatures(train_supervised[0:resp], 0)
    assert (train_supervised_features.ncol == nfeatures), 'Dimensionality of reconstruction is wrong!'
    drf_model = h2o.random_forest(x=train_supervised_features[0:20], y=train_supervised[resp], ntrees=10, min_rows=10, seed=1234)
    test_features = ae_model.deepfeatures(test_hex[0:resp], 0)
    test_features = test_features.cbind(test_hex[resp])
    cm = drf_model.confusion_matrix(test_features)
    cm.show()
    assert (abs((cm.cell_values[10][10] - 0.086)) < 0.001), 'Error. Expected 0.086, but got {0}'.format(cm.cell_values[10][10])
