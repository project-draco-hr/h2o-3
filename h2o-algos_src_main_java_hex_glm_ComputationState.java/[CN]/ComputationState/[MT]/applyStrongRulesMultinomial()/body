{
  int P=_dinfo.fullN();
  int N=P + 1;
  int selected=0;
  _activeBC=_bc;
  _activeData=_dinfo;
  _classOffsets=new int[_nclasses + 1];
  if (!_allIn && _alpha > 0) {
    if (_activeDataMultinomial == null) {
      _activeDataMultinomial=new DataInfo[_nclasses];
    }
    final double rhs=_alpha * (2 * _lambda - _previousLambda);
    int[] oldActiveCols=_activeData._activeCols == null ? new int[0] : _activeData.activeCols();
    int[] cols=MemoryManager.malloc4(N * _nclasses);
    int j=0;
    for (int c=0; c < _nclasses; ++c) {
      _classOffsets[c]=selected;
      for (int i=0; i < P; ++i) {
        if (j < oldActiveCols.length && i == oldActiveCols[j]) {
          cols[selected++]=i;
          ++j;
        }
 else         if (_ginfo._gradient[c * N + i] > rhs || _ginfo._gradient[c * N + i] < -rhs) {
          cols[selected++]=i;
        }
      }
      cols[selected++]=P;
      _activeDataMultinomial[c]=_dinfo.filterExpandedColumns(Arrays.copyOfRange(cols,_classOffsets[c],selected));
      for (int i=_classOffsets[c]; i < selected; ++i)       cols[i]+=c * N;
    }
    _allIn=_alpha == 0 || selected == cols.length;
    if (!_allIn) {
      cols=Arrays.copyOf(cols,selected);
      _beta=ArrayUtils.select(_beta,cols);
      _ginfo=new GLMGradientInfo(_ginfo._likelihood,_ginfo._objVal,ArrayUtils.select(_ginfo._gradient,cols));
    }
  }
 else   for (int c=1; c < _nclasses; ++c)   _classOffsets[c]=c * N;
  return selected;
}
