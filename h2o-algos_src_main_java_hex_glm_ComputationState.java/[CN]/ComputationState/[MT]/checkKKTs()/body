{
  if (_parms._family == Family.multinomial)   return checkKKTsMultinomial();
  double[] beta=_beta;
  if (_activeData._activeCols != null)   beta=ArrayUtils.expandAndScatter(beta,_dinfo.fullN() + 1,_activeData._activeCols);
  int[] activeCols=_activeData.activeCols();
  _gslvr=new GLMGradientSolver(_jobKey,_parms,_dinfo,(1 - _alpha) * _lambda,_bc);
  GLMGradientInfo ginfo=_gslvr.getGradient(beta);
  double[] grad=ginfo._gradient.clone();
  double err=1e-4;
  ADMM.subgrad(_alpha * _lambda,beta,grad);
  for (  int c : activeCols)   if (grad[c] > err)   err=grad[c];
 else   if (grad[c] < -err)   err=-grad[c];
  _gradientErr=err;
  _beta=beta;
  _ginfo=ginfo;
  _activeBC=null;
  if (!_allIn) {
    int[] failedCols=new int[64];
    int fcnt=0;
    for (int i=0; i < grad.length - 1; ++i) {
      if (Arrays.binarySearch(activeCols,i) >= 0)       continue;
      if (grad[i] > err || -grad[i] > err) {
        if (fcnt == failedCols.length)         failedCols=Arrays.copyOf(failedCols,failedCols.length << 1);
        failedCols[fcnt++]=i;
      }
    }
    if (fcnt > 0) {
      Log.info(fcnt + " variables failed KKT conditions, adding them to the model and recomputing.");
      final int n=activeCols.length;
      int[] newCols=Arrays.copyOf(activeCols,activeCols.length + fcnt);
      for (int i=0; i < fcnt; ++i)       newCols[n + i]=failedCols[i];
      Arrays.sort(newCols);
      _beta=ArrayUtils.select(beta,newCols);
      _ginfo=new GLMGradientInfo(ginfo._likelihood,ginfo._objVal,ArrayUtils.select(ginfo._gradient,newCols));
      _activeData=_dinfo.filterExpandedColumns(newCols);
      _activeBC=_bc.filterExpandedColumns(_activeData.activeCols());
      _gslvr=new GLMGradientSolver(_jobKey,_parms,_activeData,(1 - _alpha) * _lambda,_activeBC);
      return false;
    }
  }
  return true;
}
