{
  super.init(expensive);
  if (_parms._loading_name == null || _parms._loading_name.length() == 0)   _parms._loading_name="GLRMLoading_" + Key.rand();
  if (!_parms._loss.isForNumeric())   error("_loss",_parms._loss + " is not a univariate loss function");
  if (!_parms._multi_loss.isForCategorical())   error("_multi_loss",_parms._multi_loss + " is not a multivariate loss function");
  if (_parms._period <= 0)   error("_period","_period must be a positive integer");
  if (_parms._gamma_x < 0)   error("_gamma_x","gamma must be a non-negative number");
  if (_parms._gamma_y < 0)   error("_gamma_y","gamma_y must be a non-negative number");
  if (_parms._max_iterations < 1 || _parms._max_iterations > 1e6)   error("_max_iterations","max_iterations must be between 1 and 1e6 inclusive");
  if (_parms._init_step_size <= 0)   error("_init_step_size","init_step_size must be a positive number");
  if (_parms._min_step_size < 0 || _parms._min_step_size > _parms._init_step_size)   error("_min_step_size","min_step_size must be between 0 and " + _parms._init_step_size);
  if (_train == null)   return;
  if (_train.numCols() < 2)   error("_train","_train must have more than one column");
  _ncolY=_train.numColsExp(true,false);
  int k_min=(int)Math.min(_ncolY,_train.numRows());
  if (_ncolY > MAX_COLS_EXPANDED)   warn("_train","_train has " + _ncolY + " columns when categoricals are expanded. Algorithm may be slow.");
  if (_parms._k < 1 || _parms._k > k_min)   error("_k","_k must be between 1 and " + k_min + " inclusive");
  if (null != _parms._user_points) {
    if (_parms._init != GLRM.Initialization.User)     error("_init","init must be 'User' if providing user-specified points");
    if (_parms._user_points.get().numCols() != _train.numCols())     error("_user_points","The user-specified points must have the same number of columns (" + _train.numCols() + ") as the training observations");
 else     if (_parms._user_points.get().numRows() != _parms._k)     error("_user_points","The user-specified points must have k = " + _parms._k + " rows");
 else {
      int zero_vec=0;
      Vec[] centersVecs=_parms._user_points.get().vecs();
      for (int c=0; c < _train.numCols(); c++) {
        if (centersVecs[c].naCnt() > 0) {
          error("_user_points","The user-specified points cannot contain any missing values");
          break;
        }
 else         if (centersVecs[c].isConst() && centersVecs[c].max() == 0)         zero_vec++;
      }
      if (zero_vec == _train.numCols())       error("_user_points","The user-specified points cannot all be zero");
    }
  }
  if (null != _parms._loss_by_col) {
    if (_parms._loss_by_col.length > _train.numCols())     error("_loss_by_col","Number of loss functions specified must be <= " + _train.numCols());
 else     if (_parms._loss_by_col.length == _train.numCols())     _lossFunc=_parms._loss_by_col;
 else     if (null == _parms._loss_by_col_idx || _parms._loss_by_col.length != _parms._loss_by_col_idx.length)     error("_loss_by_col_idx","Must specify same number of column indices as loss functions");
 else {
      _lossFunc=new GLRMParameters.Loss[_train.numCols()];
      for (int i=0; i < _lossFunc.length; i++)       _lossFunc[i]=_train.vec(i).isNumeric() ? _parms._loss : _parms._multi_loss;
      for (int i=0; i < _parms._loss_by_col.length; i++) {
        int cidx=_parms._loss_by_col_idx[i];
        if (cidx < 0 || cidx >= _train.numCols())         error("_loss_by_col_idx","Column index " + cidx + " must be in [0,"+ _train.numCols()+ ")");
 else         if (_train.vec(cidx).isNumeric() && !_parms._loss_by_col[i].isForNumeric())         error("_loss_by_col","Loss function " + _parms._loss_by_col[i] + " cannot apply to numeric column "+ cidx);
 else         if (_train.vec(cidx).isEnum() && !_parms._loss_by_col[i].isForCategorical())         error("_loss_by_col","Loss function " + _parms._loss_by_col[i] + " cannot apply to categorical column "+ cidx);
 else         _lossFunc[_parms._loss_by_col_idx[i]]=_parms._loss_by_col[i];
      }
    }
  }
 else {
    if (null != _parms._loss_by_col_idx)     error("_loss_by_col","Must specify loss function for each column");
 else {
      _lossFunc=new GLRMParameters.Loss[_train.numCols()];
      for (int i=0; i < _lossFunc.length; i++)       _lossFunc[i]=_train.vec(i).isNumeric() ? _parms._loss : _parms._multi_loss;
    }
  }
  _ncolX=_parms._k;
  _ncolA=_train.numCols();
}
