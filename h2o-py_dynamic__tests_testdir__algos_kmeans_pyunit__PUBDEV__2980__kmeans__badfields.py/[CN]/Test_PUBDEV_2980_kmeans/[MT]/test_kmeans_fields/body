def test_kmeans_fields(self):
    "\n        test_kmeans_grid_search_over_validation_datasets performs the following:\n        a. build H2O kmeans models using grid search.  Count and make sure models\n           are only built for hyper-parameters set to legal values.  No model is built for bad hyper-parameters\n           values.  We should instead get a warning/error message printed out.\n        b. For each model built using grid search, we will extract the parameters used in building\n           that model and manually build a H2O kmeans model.  Training metrics are calculated from the\n           gridsearch model and the manually built model.  If their metrics\n           differ by too much, print a warning message but don't fail the test.\n        c. we will check and make sure the models are built within the max_runtime_secs time limit that was set\n           for it as well.  If max_runtime_secs was exceeded, declare test failure.\n        "
    print('*******************************************************************************************')
    h2o.cluster_info()
    good_params_list = {'init': 'Furthest', 'seed': 1464887902, 'max_iterations': 10, 'k': 10, }
    good_model_params = {'max_runtime_secs': 0.04326415543999999, }
    good_model = H2OKMeansEstimator(**good_params_list)
    good_model.train(x=self.x_indices, training_frame=self.training1_data, **good_model_params)
    bad_params_list = {'init': 'Random', 'seed': 1464888628, 'k': 6, 'max_iterations': 0, }
    bad_model_params = {'max_runtime_secs': 0.007948218600000001, }
    bad_model = H2OKMeansEstimator(**bad_params_list)
    bad_model.train(x=self.x_indices, training_frame=self.training1_data, **bad_model_params)
    print("good_model._model_json['output']['model_summary'] type is {0}.  bad_model._model_json['output']['model_summary'] type is {1}".format(type(good_model._model_json['output']['model_summary']), type(bad_model._model_json['output']['model_summary'])))
    print('They are not equal for some reason....')
