{
  final DatumReader<GenericRecord> datumReader=new GenericDatumReader<>();
  final H2OSeekableInputAdaptor sbai=new H2OSeekableInputAdaptor(cidx,din);
  DataFileReader<GenericRecord> dataFileReader=null;
  int cnt=0;
  try {
    DataFileStream.Header fakeHeader=new DataFileReader<>(new SeekableByteArrayInput(this.header),datumReader).getHeader();
    dataFileReader=DataFileReader.openReader(sbai,datumReader,fakeHeader,true);
    Schema schema=dataFileReader.getSchema();
    GenericRecord gr=new GenericData.Record(schema);
    Schema.Field[] flatSchema=flatSchema(schema);
    long sync=dataFileReader.previousSync();
    if (sbai.chunkCnt == 0) {
      while (dataFileReader.hasNext() && dataFileReader.previousSync() == sync) {
        gr=dataFileReader.next(gr);
        write2frame(gr,_setup.getColumnNames(),flatSchema,_setup.getColumnTypes(),dout);
        cnt++;
      }
    }
  }
 catch (  Throwable e) {
    e.printStackTrace();
  }
  Log.trace(String.format("Avro: ChunkIdx: %d read %d records, start at %d off, block count: %d, block size: %d",cidx,cnt,din.getChunkDataStart(cidx),dataFileReader.getBlockCount(),dataFileReader.getBlockSize()));
  return dout;
}
