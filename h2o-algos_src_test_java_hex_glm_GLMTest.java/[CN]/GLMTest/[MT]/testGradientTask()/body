{
  GLM job=null;
  Key parsed=Key.make("cars_parsed");
  Key modelKey=Key.make("cars_model");
  Frame fr=null;
  GLMModel model=null;
  Frame score=null;
  DataInfo dinfo=null;
  try {
    fr=parse_test_file(parsed,"smalldata/junit/mixcat_train.csv");
    GLMParameters params=new GLMParameters(Family.binomial,Family.binomial.defaultLink,new double[]{0},new double[]{0});
    params._train=parsed;
    params._lambda=new double[]{0};
    params._use_all_factor_levels=true;
    fr.add("Useless",fr.remove("Useless"));
    dinfo=new DataInfo(Key.make(),fr,null,1,params._use_all_factor_levels || params._lambda_search,params._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE,DataInfo.TransformType.NONE);
    DKV.put(dinfo._key,dinfo);
    double ymu=0;
    double[][] beta=new double[5][];
    for (int i=0; i < beta.length; ++i)     beta[i]=MemoryManager.malloc8d(dinfo.fullN() + 1);
    Random rnd=new Random(987654321);
    for (int i=0; i < beta.length; ++i)     for (int j=0; j < beta[i].length; ++j)     beta[i][j]=1 - 2 * rnd.nextDouble();
    GLMIterationTask[] glmts=new GLMIterationTask[beta.length];
    for (int i=0; i < beta.length; ++i)     glmts[i]=new GLMTask.GLMIterationTask(null,dinfo,params,false,true,true,beta[i],ymu,1,ModelUtils.DEFAULT_THRESHOLDS,null).doAll(dinfo._adaptedFrame);
    ColGradientTask grt=new ColGradientTask(dinfo,params,beta,1).doAll(dinfo._adaptedFrame);
    for (int i=0; i < beta.length; ++i) {
      for (int j=0; j < beta[i].length; ++j)       assertEquals("gradients differ: " + Arrays.toString(glmts[i]._grad) + " != "+ Arrays.toString(grt._gradient[i]),glmts[i]._grad[j],grt._gradient[i][j],1e-4);
    }
    params=new GLMParameters(Family.gaussian,Family.gaussian.defaultLink,new double[]{0},new double[]{0});
    params._use_all_factor_levels=false;
    dinfo.remove();
    dinfo=new DataInfo(Key.make(),fr,null,1,params._use_all_factor_levels || params._lambda_search,params._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE,DataInfo.TransformType.NONE);
    DKV.put(dinfo._key,dinfo);
    beta=new double[5][];
    for (int i=0; i < beta.length; ++i)     beta[i]=MemoryManager.malloc8d(dinfo.fullN() + 1);
    rnd=new Random(1987654321);
    for (int i=0; i < beta.length; ++i)     for (int j=0; j < beta[i].length; ++j)     beta[i][j]=1 - 2 * rnd.nextDouble();
    glmts=new GLMIterationTask[beta.length];
    for (int i=0; i < beta.length; ++i)     glmts[i]=new GLMTask.GLMIterationTask(null,dinfo,params,false,true,true,beta[i],ymu,1,ModelUtils.DEFAULT_THRESHOLDS,null).doAll(dinfo._adaptedFrame);
    grt=new ColGradientTask(dinfo,params,beta,1).doAll(dinfo._adaptedFrame);
    for (int i=0; i < beta.length; ++i) {
      for (int j=0; j < beta[i].length; ++j)       assertEquals("gradients differ: " + Arrays.toString(glmts[i]._grad) + " != "+ Arrays.toString(grt._gradient[i]),glmts[i]._grad[j],grt._gradient[i][j],1e-4);
    }
    dinfo.remove();
    fr=parse_test_file(parsed,"smalldata/junit/cars.csv");
    params=new GLMParameters(Family.poisson,Family.poisson.defaultLink,new double[]{0},new double[]{0});
    params._train=parsed;
    params._lambda=new double[]{0};
    params._use_all_factor_levels=true;
    dinfo=new DataInfo(Key.make(),fr,null,1,params._use_all_factor_levels || params._lambda_search,params._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE,DataInfo.TransformType.NONE);
    DKV.put(dinfo._key,dinfo);
    ymu=0;
    beta=new double[5][];
    for (int i=0; i < beta.length; ++i)     beta[i]=MemoryManager.malloc8d(dinfo.fullN() + 1);
    rnd=new Random(987654321);
    for (int i=0; i < beta.length; ++i)     for (int j=0; j < beta[i].length; ++j)     beta[i][j]=1 - 2 * rnd.nextDouble();
    glmts=new GLMIterationTask[beta.length];
    for (int i=0; i < beta.length; ++i)     glmts[i]=new GLMTask.GLMIterationTask(null,dinfo,params,false,true,true,beta[i],ymu,1,ModelUtils.DEFAULT_THRESHOLDS,null).doAll(dinfo._adaptedFrame);
    grt=new ColGradientTask(dinfo,params,beta,1).doAll(dinfo._adaptedFrame);
    for (int i=0; i < beta.length; ++i) {
      for (int j=0; j < beta[i].length; ++j)       assertEquals("gradients differ: " + Arrays.toString(glmts[i]._grad) + " != "+ Arrays.toString(grt._gradient[i]),glmts[i]._grad[j],grt._gradient[i][j],1e-4);
    }
    dinfo.remove();
    fr=parse_test_file(parsed,"smalldata/glm_test/arcene.csv");
    params=new GLMParameters(Family.gaussian,Family.gaussian.defaultLink,new double[]{0},new double[]{0});
    params._train=parsed;
    params._lambda=new double[]{0};
    params._use_all_factor_levels=true;
    dinfo=new DataInfo(Key.make(),fr,null,1,params._use_all_factor_levels || params._lambda_search,params._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE,DataInfo.TransformType.NONE);
    DKV.put(dinfo._key,dinfo);
    ymu=0;
    beta=new double[1][];
    for (int i=0; i < beta.length; ++i)     beta[i]=MemoryManager.malloc8d(dinfo.fullN() + 1);
    rnd=new Random(987654321);
    for (int i=0; i < beta.length; ++i)     for (int j=0; j < beta[i].length; ++j)     beta[i][j]=1 - 2 * rnd.nextDouble();
    glmts=new GLMIterationTask[beta.length];
    for (int i=0; i < beta.length; ++i)     glmts[i]=new GLMTask.GLMIterationTask(null,dinfo,params,false,true,true,beta[i],ymu,1,ModelUtils.DEFAULT_THRESHOLDS,null).doAll(dinfo._adaptedFrame);
    grt=new ColGradientTask(dinfo,params,beta,1).doAll(dinfo._adaptedFrame);
    for (int i=0; i < beta.length; ++i) {
      for (int j=0; j < beta[i].length; ++j)       assertEquals("gradients differ",glmts[i]._grad[j],grt._gradient[i][j],1e-4);
    }
  }
  finally {
    if (fr != null)     fr.delete();
    if (score != null)     score.delete();
    if (model != null)     model.delete();
    if (job != null)     job.remove();
    if (dinfo != null)     dinfo.remove();
  }
}
