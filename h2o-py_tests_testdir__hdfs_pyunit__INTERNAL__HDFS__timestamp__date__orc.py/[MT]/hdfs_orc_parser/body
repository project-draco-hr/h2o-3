def hdfs_orc_parser():
    hadoop_namenode_is_accessible = pyunit_utils.hadoop_namenode_is_accessible()
    if hadoop_namenode_is_accessible:
        hdfs_name_node = pyunit_utils.hadoop_namenode()
        if pyunit_utils.cannaryHDFSTest(hdfs_name_node, '/datasets/orc_parser/orc/orc_split_elim.orc'):
            print('Your hive-exec version is too old.  Orc parser test {0} is skipped.'.format('pyunit_INTERNAL_HDFS_timestamp_date_orc.py'))
            pass
        else:
            tol_time = 200
            tol_numeric = 1e-05
            numElements2Compare = 100
            allOrcFiles = ['/datasets/orc_parser/orc/TestOrcFile.testDate1900.orc', '/datasets/orc_parser/orc/TestOrcFile.testDate2038.orc', '/datasets/orc_parser/orc/orc_split_elim.orc']
            allCsvFiles = ['/datasets/orc_parser/csv/TestOrcFile.testDate1900.csv', '/datasets/orc_parser/csv/TestOrcFile.testDate2038.csv', '/datasets/orc_parser/csv/orc_split_elim.csv']
            for fIndex in range(len(allOrcFiles)):
                url_orc = 'hdfs://{0}{1}'.format(hdfs_name_node, allOrcFiles[fIndex])
                url_csv = 'hdfs://{0}{1}'.format(hdfs_name_node, allCsvFiles[fIndex])
                h2oOrc = h2o.import_file(url_orc)
                h2oCsv = h2o.import_file(url_csv)
                assert pyunit_utils.compare_frames(h2oOrc, h2oCsv, numElements2Compare, tol_time, tol_numeric), 'H2O frame parsed from orc and csv files are different!'
    else:
        raise EnvironmentError
