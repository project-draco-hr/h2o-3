{
  if (source.numCols() <= 1)   throw new IllegalArgumentException("Training data must have at least 2 features (incl. response).");
  if (hidden == null)   throw new IllegalArgumentException("There must be at least one hidden layer.");
  for (  int aHidden : hidden) {
    if (aHidden == 0)     throw new IllegalArgumentException("Hidden layer size must be >0.");
  }
  if (hidden_dropout_ratios == null) {
    hidden_dropout_ratios=new double[hidden.length];
    if (activation == Activation.TanhWithDropout || activation == Activation.MaxoutWithDropout || activation == Activation.RectifierWithDropout) {
      if (!quiet_mode)       Log.info("Automatically setting all hidden dropout ratios to 0.5.");
      Arrays.fill(hidden_dropout_ratios,0.5);
    }
  }
 else   if (hidden_dropout_ratios.length != hidden.length)   throw new IllegalArgumentException("Must have " + hidden.length + " hidden layer dropout ratios.");
 else   if (hidden_dropout_ratios != null) {
    if (activation != Activation.TanhWithDropout && activation != Activation.MaxoutWithDropout && activation != Activation.RectifierWithDropout) {
      if (!quiet_mode)       Log.info("Ignoring hidden_dropout_ratios because a non-Dropout activation function was specified.");
    }
  }
  if (!quiet_mode) {
    if (adaptive_rate) {
      Log.info("Using automatic learning rate.  Ignoring the following input parameters:");
      Log.info("  rate, rate_decay, rate_annealing, momentum_start, momentum_ramp, momentum_stable, nesterov_accelerated_gradient.");
    }
 else {
      Log.info("Using manual learning rate.  Ignoring the following input parameters:");
      Log.info("  rho, epsilon.");
    }
    if (initial_weight_distribution == InitialWeightDistribution.UniformAdaptive) {
      Log.info("Ignoring initial_weight_scale for UniformAdaptive weight distribution.");
    }
  }
  if (loss == Loss.Automatic) {
    if (!classification) {
      if (!quiet_mode)       Log.info("Automatically setting loss to MeanSquare for regression.");
      loss=Loss.MeanSquare;
    }
 else {
      if (!quiet_mode)       Log.info("Automatically setting loss to Cross-Entropy for classification.");
      loss=Loss.CrossEntropy;
    }
  }
  if (!classification && loss == Loss.CrossEntropy)   throw new IllegalArgumentException("Cannot use CrossEntropy loss function for regression.");
  if (!sparse && col_major) {
    if (!quiet_mode)     throw new IllegalArgumentException("Cannot use column major storage for non-sparse data handling.");
  }
}
