{
  if (_jobKey.get().stop_requested())   return;
  final int nrows=chunks[0]._len;
  final long offset=chunks[0].start();
  boolean doWork=chunkInit();
  if (!doWork)   return;
  final boolean obs_weights=_dinfo._weights && !_fr.vecs()[_dinfo.weightChunkId()].isConst() && !(_fr.vecs()[_dinfo.weightChunkId()].isBinary());
  final double global_weight_sum=obs_weights ? Math.round(_fr.vecs()[_dinfo.weightChunkId()].mean() * _fr.numRows()) : 0;
  DataInfo.Row row=null;
  DataInfo.Row[] rows=null;
  if (_sparse)   rows=_dinfo.extractSparseRows(chunks);
 else   row=_dinfo.newDenseRow();
  double[] weight_map=null;
  double relative_chunk_weight=1;
  if (obs_weights) {
    weight_map=new double[nrows];
    double weight_sum=0;
    for (int i=0; i < nrows; ++i) {
      row=_sparse ? rows[i] : _dinfo.extractDenseRow(chunks,i,row);
      weight_sum+=row.weight;
      weight_map[i]=weight_sum;
      assert(i == 0 || row.weight == 0 || weight_map[i] > weight_map[i - 1]);
    }
    if (weight_sum > 0) {
      ArrayUtils.div(weight_map,weight_sum);
      relative_chunk_weight=global_weight_sum * nrows / _fr.numRows() / weight_sum;
    }
 else     return;
  }
  final int repeats=(int)Math.ceil(_useFraction * relative_chunk_weight);
  final float fraction=(float)(_useFraction * relative_chunk_weight) / repeats;
  assert(fraction <= 1.0);
  final boolean sample=(fraction < 0.999 || obs_weights || _shuffle);
  final long chunkSeed=(0x8734093502429734L + _seed + offset) * (_iteration + 0x9823423497823423L);
  final Random skip_rng=sample ? RandomUtils.getRNG(chunkSeed) : null;
  int[] shufIdx=skip_rng == null ? null : new int[nrows];
  if (skip_rng != null) {
    for (int i=0; i < nrows; ++i)     shufIdx[i]=i;
    ArrayUtils.shuffleArray(shufIdx,skip_rng);
  }
  double[] responses=new double[getMiniBatchSize()];
  double[] offsets=new double[getMiniBatchSize()];
  long seed=0;
  final int miniBatchSize=getMiniBatchSize();
  long num_processed_rows=0;
  long num_skipped_rows=0;
  int miniBatchCounter=0;
  for (int rep=0; rep < repeats; ++rep) {
    for (int row_idx=0; row_idx < nrows; ++row_idx) {
      int r=sample ? -1 : 0;
      if (sample && !obs_weights && skip_rng.nextDouble() > fraction)       continue;
      if (obs_weights && num_processed_rows % 2 == 0) {
        double key=skip_rng.nextDouble();
        r=Arrays.binarySearch(weight_map,0,nrows,key);
        if (r < 0)         r=-r - 1;
        assert(r == 0 || weight_map[r] > weight_map[r - 1]);
      }
 else       if (r == -1) {
        r=shufIdx[row_idx];
        while (obs_weights && ((r == 0 && weight_map[r] == 0) || (r > 0 && weight_map[r] == weight_map[r - 1]))) {
          r=skip_rng.nextInt(nrows);
        }
      }
 else {
        assert(!obs_weights);
        r=row_idx;
      }
      assert(r >= 0 && r <= nrows);
      row=_sparse ? rows[r] : _dinfo.extractDenseRow(chunks,r,row);
      if (row.bad || row.weight == 0) {
        num_skipped_rows++;
        continue;
      }
 else {
        assert(row.weight > 0);
        seed=offset + rep * nrows + r;
        if (outputs != null && outputs.length > 0) {
          assert(miniBatchSize == 0);
          processRow(seed,row,outputs);
        }
 else {
          if (miniBatchSize > 0) {
            processRow(seed,row,miniBatchCounter);
            responses[miniBatchCounter]=row.response != null && row.response.length > 0 ? row.response(0) : 0;
            offsets[miniBatchCounter]=row.offset;
            miniBatchCounter++;
          }
 else           processRow(seed,row);
        }
      }
      num_processed_rows++;
      if (miniBatchCounter > 0 && miniBatchCounter % miniBatchSize == 0) {
        processMiniBatch(seed,responses,offsets,miniBatchCounter);
        miniBatchCounter=0;
      }
    }
  }
  if (miniBatchCounter > 0) {
    processMiniBatch(seed,responses,offsets,miniBatchCounter);
  }
  assert(fraction != 1 || num_processed_rows + num_skipped_rows == repeats * nrows);
  chunkDone(num_processed_rows);
}
