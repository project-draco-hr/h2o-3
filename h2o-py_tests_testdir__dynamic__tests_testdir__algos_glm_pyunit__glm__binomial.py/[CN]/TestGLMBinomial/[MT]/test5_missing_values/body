def test5_missing_values(self):
    '\n        Test parameter missing_values_handling="MeanImputation" with\n        only real value predictors.  The same data sets as before is used.  However, we\n        go into the predictor matrix and randomly decide to replace a value with\n        nan and create missing values.  Sklearn logistic regression model is built using the\n        data set where we have imputed the missing values.  This Sklearn model will be used to\n        compare our H2O models with.\n        '
    print('*******************************************************************************************')
    print('Test5: test the GLM with imputation of missing values with column averages.')
    (p_weights, p_logloss_train, p_cm_train, p_accuracy_training, p_logloss_test, p_cm_test, p_accuracy_test) = self.sklearn_binomial_result(self.training_data_file_nans, self.test_data_file_nans, False, False)
    training_data = h2o.import_file(pyunit_utils.locate(self.training_data_file_nans))
    test_data = h2o.import_file(pyunit_utils.locate(self.test_data_file_nans))
    training_data[self.y_index] = training_data[self.y_index].asfactor()
    test_data[self.y_index] = test_data[self.y_index].asfactor()
    model_h2o = H2OGeneralizedLinearEstimator(family=self.family, Lambda=0, missing_values_handling='MeanImputation')
    model_h2o.train(x=self.x_indices, y=self.y_index, training_frame=training_data)
    h2o_model_test_metrics = model_h2o.model_performance(test_data=test_data)
    num_test_failed = self.test_failed
    self.test_failed = pyunit_utils.extract_comparison_attributes_and_print_multinomial(model_h2o, h2o_model_test_metrics, self.family, '\nTest5 Done!', compare_att_str=['\nComparing intercept and weights ....', '\nComparing logloss from training dataset ....', '\nComparing logloss from test dataset ....', '\nComparing confusion matrices from training dataset ....', '\nComparing confusion matrices from test dataset ...', '\nComparing accuracy from training dataset ....', '\nComparing accuracy from test dataset ....'], h2o_att_str=['H2O missing values intercept and weights: \n', 'H2O missing values logloss from training dataset: ', 'H2O missing values logloss from test dataset', 'H2O missing values confusion matrix from training dataset: \n', 'H2O missing values confusion matrix from test dataset: \n', 'H2O missing values accuracy from training dataset: ', 'H2O missing values accuracy from test dataset: '], template_att_str=['Sklearn missing values intercept and weights: \n', 'Sklearn missing values logloss from training dataset: ', 'Sklearn missing values logloss from test dataset: ', 'Sklearn missing values confusion matrix from training dataset: \n', 'Sklearn missing values confusion matrix from test dataset: \n', 'Sklearn missing values accuracy from training dataset: ', 'Sklearn missing values accuracy from test dataset: '], att_str_fail=['Intercept and weights are not equal!', 'Logloss from training dataset differ too much!', 'Logloss from test dataset differ too much!', '', '', 'Accuracies from training dataset differ too much!', 'Accuracies from test dataset differ too much!'], att_str_success=['Intercept and weights are close enough!', 'Logloss from training dataset are close enough!', 'Logloss from test dataset are close enough!', '', '', 'Accuracies from training dataset are close enough!', 'Accuracies from test dataset are close enough!'], can_be_better_than_template=[False, True, True, False, False, True, True], just_print=[True, True, True, True, True, True, False], failed_test_number=self.test_failed, template_params=[p_weights, p_logloss_train, p_cm_train, p_accuracy_training, p_logloss_test, p_cm_test, p_accuracy_test], ignored_eps=self.ignored_eps, allowed_diff=self.allowed_diff)
    self.test_failed_array[self.test_num] += pyunit_utils.show_test_results('test5_missing_values', num_test_failed, self.test_failed)
    self.test_num += 1
