def test_gbm_grid_search_over_params(self):
    "\n        test_gbm_grid_search_over_params performs the following:\n        a. Next, build H2O GBM models using grid search.  Count and make sure models\n           are only built for hyper-parameters set to legal values.  No model is built for bad hyper-parameters\n           values.  We should instead get a warning/error message printed out.\n        b. For each model built using grid search, we will extract the parameters used in building\n           that model and manually build a H2O GBM model.  Training metrics are calculated from the\n           gridsearch model and the manually built model.  If their metrics\n           differ by too much, print a warning message but don't fail the test.\n        c. we will check and make sure the models are built within the max_runtime_secs time limit that was set\n           for it as well.  If max_runtime_secs was exceeded, declare test failure.\n        "
    print('*******************************************************************************************')
    print(('test_gbm_grid_search_over_params for GBM ' + self.family))
    h2o.cluster_info()
    try:
        print('Hyper-parameters used here is {0}'.format(self.final_hyper_params))
        grid_model = H2OGridSearch(H2OGradientBoostingEstimator(distribution=self.family, nfolds=self.nfolds), hyper_params=self.final_hyper_params)
        grid_model.train(x=self.x_indices, y=self.y_index, training_frame=self.training1_data)
        self.correct_model_number = len(grid_model)
        if (not (self.correct_model_number == self.possible_number_models)):
            self.test_failed += 1
            print('test_gbm_grid_search_over_params for GBM failed: number of models built by gridsearch does not equal to all possible combinations of hyper-parameters')
        else:
            params_dict = dict()
            params_dict['distribution'] = self.family
            params_dict['nfolds'] = self.nfolds
            total_run_time_limits = 0.0
            true_run_time_limits = 0.0
            manual_run_runtime = 0.0
            for each_model in grid_model:
                params_list = grid_model.get_hyperparams_dict(each_model._id)
                params_list.update(params_dict)
                model_params = dict()
                if ('max_runtime_secs' in params_list):
                    model_params['max_runtime_secs'] = params_list['max_runtime_secs']
                    max_runtime = params_list['max_runtime_secs']
                    del params_list['max_runtime_secs']
                else:
                    max_runtime = 0
                if ('r2_stopping' in params_list):
                    model_params['r2_stopping'] = params_list['r2_stopping']
                    del params_list['r2_stopping']
                if ('validation_frame' in params_list):
                    model_params['validation_frame'] = params_list['validation_frame']
                    del params_list['validation_frame']
                if ('learn_rate_annealing' in params_list):
                    model_params['learn_rate_annealing'] = params_list['learn_rate_annealing']
                    del params_list['learn_rate_annealing']
                each_model_runtime = pyunit_utils.find_grid_runtime([each_model])
                manual_model = H2OGradientBoostingEstimator(**params_list)
                manual_model.train(x=self.x_indices, y=self.y_index, training_frame=self.training1_data, **model_params)
                model_runtime = pyunit_utils.find_grid_runtime([manual_model])
                manual_run_runtime += model_runtime
                summary_list = manual_model._model_json['output']['model_summary']
                tree_num = summary_list.cell_values['number_of_trees'][0]
                if (max_runtime > 0):
                    if ((max_runtime < self.min_runtime_per_tree) or (tree_num <= 1)):
                        total_run_time_limits += model_runtime
                    else:
                        total_run_time_limits += max_runtime
                true_run_time_limits += max_runtime
                grid_model_metrics = each_model.model_performance()._metric_json[self.training_metric]
                manual_model_metrics = manual_model.model_performance()._metric_json[self.training_metric]
                if (not ((type(grid_model_metrics) == str) or (type(manual_model_metrics) == str))):
                    if ((abs(grid_model_metrics) > 0) and ((abs((grid_model_metrics - manual_model_metrics)) / grid_model_metrics) > self.allowed_diff)):
                        print('test_gbm_grid_search_over_params for GBM warning: grid search model mdetric ({0}) and manually built H2O model metric ({1}) differ too much!'.format(grid_model_metrics, manual_model_metrics))
            total_run_time_limits = (max(total_run_time_limits, true_run_time_limits) * (1 + self.extra_time_fraction))
            if (not (manual_run_runtime <= total_run_time_limits)):
                self.test_failed += 1
                print('test_gbm_grid_search_over_params for GBM failed: time taken to manually build models is {0}.  Maximum allowed time is {1}'.format(manual_run_runtime, total_run_time_limits))
            else:
                print('time taken to manually build all models is {0}. Maximum allowed time is {1}'.format(manual_run_runtime, total_run_time_limits))
            if (self.test_failed == 0):
                print('test_gbm_grid_search_over_params for GBM has passed!')
    except:
        if (self.possible_number_models > 0):
            print('test_gbm_grid_search_over_params for GBM failed: exception was thrown for no reason.')
            self.test_failed += 1
