{
  if (_parms._checkpoint != null)   return;
  long p=_train.degreesOfFreedom() - (_parms._autoencoder ? 0 : _train.lastVec().cardinality());
  String[][] dom=_train.domains();
  for (int i=0; i < _train.numCols() - (_parms._autoencoder ? 0 : 1); ++i) {
    if (dom[i] != null) {
      p++;
    }
  }
  long output=_parms._autoencoder ? p : Math.abs(_train.lastVec().cardinality());
  long model_size=p * _parms._hidden[0];
  int layer=1;
  for (; layer < _parms._hidden.length; ++layer)   model_size+=_parms._hidden[layer - 1] * _parms._hidden[layer];
  model_size+=_parms._hidden[layer - 1] * output;
  for (layer=0; layer < _parms._hidden.length; ++layer)   model_size+=_parms._hidden[layer];
  model_size+=output;
  if (model_size > 1e8) {
    String msg="Model is too large: " + model_size + " parameters. Try reducing the number of neurons in the hidden layers (or reduce the number of categorical factors).";
    error("_hidden",msg);
  }
}
