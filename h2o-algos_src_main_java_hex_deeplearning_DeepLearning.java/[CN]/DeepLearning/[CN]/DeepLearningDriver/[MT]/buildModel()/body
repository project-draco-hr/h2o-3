{
  Scope.enter();
  DeepLearningModel cp=null;
  if (_parms._checkpoint == null) {
    cp=new DeepLearningModel(dest(),_parms,new DeepLearningModel.DeepLearningModelOutput(DeepLearning.this),_train,_valid);
    cp.model_info().initializeMembers();
  }
 else {
    final DeepLearningModel previous=DKV.getGet(_parms._checkpoint);
    if (previous == null)     throw new IllegalArgumentException("Checkpoint not found.");
    Log.info("Resuming from checkpoint.");
    new ProgressUpdate("Resuming from checkpoint").fork(_progressKey);
    if (isClassifier() != previous._output.isClassifier())     throw new IllegalArgumentException("Response type must be the same as for the checkpointed model.");
    if (isSupervised() != previous._output.isSupervised())     throw new IllegalArgumentException("Model type must be the same as for the checkpointed model.");
    DeepLearningParameters oldP=previous._parms;
    DeepLearningParameters newP=_parms;
    DeepLearningParameters.Sanity.checkpoint(oldP,newP);
    try {
      final DataInfo dinfo=makeDataInfo(_train,_valid,_parms);
      DKV.put(dinfo);
      cp=new DeepLearningModel(dest(),_parms,previous,false,dinfo);
      cp.write_lock(self());
      if (!Arrays.equals(cp._output._names,previous._output._names)) {
        throw new IllegalArgumentException("Predictor columns of the training data must be the same as for the checkpointed model. Check ignored columns.");
      }
      if (!Arrays.deepEquals(cp._output._domains,previous._output._domains)) {
        throw new IllegalArgumentException("Categorical factor levels of the training data must be the same as for the checkpointed model.");
      }
      if (dinfo.fullN() != previous.model_info().data_info().fullN()) {
        throw new IllegalArgumentException("Total number of predictors is different than for the checkpointed model.");
      }
      final DeepLearningParameters actualNewP=cp.model_info().get_params();
      assert(actualNewP != previous.model_info().get_params());
      assert(actualNewP != newP);
      assert(actualNewP != oldP);
      DeepLearningParameters.Sanity.update(actualNewP,newP,isClassifier());
      actualNewP._epochs+=previous.epoch_counter;
      Log.info("Adding " + String.format("%.3f",previous.epoch_counter) + " epochs from the checkpointed model.");
      if (actualNewP._nfolds != 0) {
        Log.info("Disabling cross-validation: Not supported when resuming training from a checkpoint.");
        H2O.unimpl("writing to n_folds field needs to be uncommented");
      }
      cp.update(self());
    }
  finally {
      if (cp != null)       cp.unlock(self());
    }
  }
  trainModel(cp);
  List<Key> keep=new ArrayList<>();
  keep.add(dest());
  keep.add(cp.model_info().data_info()._key);
  keep.add(cp._output._training_metrics._key);
  if (cp._output._validation_metrics != null) {
    keep.add(cp._output._validation_metrics._key);
  }
  if (cp._output.weights != null && cp._output.biases != null) {
    for (    Key k : Arrays.asList(cp._output.weights)) {
      keep.add(k);
      for (      Vec vk : ((Frame)DKV.getGet(k)).vecs()) {
        keep.add(vk._key);
      }
    }
    for (    Key k : Arrays.asList(cp._output.biases)) {
      keep.add(k);
      for (      Vec vk : ((Frame)DKV.getGet(k)).vecs()) {
        keep.add(vk._key);
      }
    }
  }
  Scope.exit(keep.toArray(new Key[0]));
}
