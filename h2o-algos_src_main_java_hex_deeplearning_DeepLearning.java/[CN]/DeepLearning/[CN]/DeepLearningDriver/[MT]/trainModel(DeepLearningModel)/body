{
  Frame validScoreFrame=null;
  Frame train, trainScoreFrame;
  try {
    lock_data();
    if (model == null) {
      model=DKV.get(dest()).get();
    }
    model.write_lock(self());
    final DeepLearningModel.DeepLearningParameters mp=model._parms;
    ValidationAdapter validAdapter=new ValidationAdapter(_parms._validation_frame,_parms.classification);
    validAdapter.prepareValidationWithModel(model);
    final long model_size=model.model_info().size();
    if (!_parms.quiet_mode)     Log.info("Number of model parameters (weights/biases): " + String.format("%,d",model_size));
    train=model.model_info().data_info()._adaptedFrame;
    if (mp.force_load_balance)     train=reBalance(train,mp.replicate_training_data);
    float[] trainSamplingFactors;
    if (mp.classification && mp.balance_classes) {
      trainSamplingFactors=new float[train.lastVec().domain().length];
      train=sampleFrameStratified(train,train.lastVec(),trainSamplingFactors,(long)(mp.max_after_balance_size * train.numRows()),mp.seed,true,false);
      model.setModelClassDistribution(new MRUtils.ClassDist(train.lastVec()).doAll(train.lastVec()).rel_dist());
    }
    model.training_rows=train.numRows();
    trainScoreFrame=sampleFrame(train,mp.score_training_samples,mp.seed);
    if (!_parms.quiet_mode)     Log.info("Number of chunks of the training data: " + train.anyVec().nChunks());
    if (_parms._validation_frame != null) {
      model.validation_rows=_parms._validation_frame.numRows();
      Frame adaptedValid=validAdapter.getValidation();
      if (validAdapter.getValidAdaptor().needsAdaptation2CM()) {
        int rIndex=0;
        for (int i=0; i < _parms._training_frame.names().length; i++) {
          if (_parms._training_frame._names[i] == _parms.response_column)           rIndex=i;
        }
        final String responseName=_parms._training_frame._names != null && rIndex >= 0 ? _parms._training_frame._names[rIndex] : "response_vec";
        adaptedValid.add(validAdapter.getValidAdaptor().adaptedValidationResponse(responseName),validAdapter.getValidAdaptor().getAdaptedValidationResponse2CM());
      }
      if (mp.classification && mp.balance_classes && mp.score_validation_sampling == DeepLearningModel.DeepLearningParameters.ClassSamplingMethod.Stratified) {
        validScoreFrame=sampleFrameStratified(adaptedValid,adaptedValid.lastVec(),null,mp.score_validation_samples > 0 ? mp.score_validation_samples : adaptedValid.numRows(),mp.seed + 1,false,false);
      }
 else {
        validScoreFrame=sampleFrame(adaptedValid,mp.score_validation_samples,mp.seed + 1);
      }
      if (mp.force_load_balance)       validScoreFrame=reBalance(validScoreFrame,false);
      if (!_parms.quiet_mode)       Log.info("Number of chunks of the validation data: " + validScoreFrame.anyVec().nChunks());
    }
    model.actual_train_samples_per_iteration=computeTrainSamplesPerIteration(mp,train.numRows(),model);
    if (mp.replicate_training_data && (model.actual_train_samples_per_iteration == train.numRows() * (mp.single_node_mode ? 1 : H2O.CLOUD.size())) && !mp.shuffle_training_data&& H2O.CLOUD.size() > 1) {
      Log.warn("Enabling training data shuffling, because all nodes train on the full dataset (replicated training data).");
      mp.shuffle_training_data=true;
    }
    model._timeLastScoreEnter=System.currentTimeMillis();
    if (!mp.quiet_mode)     Log.info("Initial model:\n" + model.model_info());
    if (_parms.autoencoder)     model.doScoring(train,trainScoreFrame,validScoreFrame,self(),validAdapter.getValidAdaptor());
    model.update(self());
    Log.info("Starting to train the Deep Learning model.");
    do {
      model.set_model_info(mp.epochs == 0 ? model.model_info() : H2O.CLOUD.size() > 1 && mp.replicate_training_data ? (mp.single_node_mode ? new DeepLearningTask2(self(),train,model.model_info(),rowFraction(train,mp,model)).doAll(Key.make()).model_info() : new DeepLearningTask2(self(),train,model.model_info(),rowFraction(train,mp,model)).doAllNodes().model_info()) : new DeepLearningTask(self(),model.model_info(),rowFraction(train,mp,model)).doAll(train).model_info());
      update(model.actual_train_samples_per_iteration);
      if (!mp.quiet_mode)       Log.info("Progress: " + PrettyPrint.formatPct(progress()));
    }
 while (model.doScoring(train,trainScoreFrame,validScoreFrame,self(),validAdapter.getValidAdaptor()));
    if (!isCancelledOrCrashed() && _parms.override_with_best_model && model.actual_best_model_key != null && _parms.n_folds == 0) {
      DeepLearningModel best_model=DKV.get(model.actual_best_model_key).get();
      if (best_model != null && best_model.error() < model.error() && Arrays.equals(best_model.model_info().units,model.model_info().units)) {
        Log.info("Setting the model to be the best model so far (based on scoring history).");
        DeepLearningModel.DeepLearningModelInfo mi=best_model.model_info().deep_clone();
        mi.set_processed_global(model.model_info().get_processed_global());
        mi.set_processed_local(model.model_info().get_processed_local());
        model.set_model_info(mi);
        model.update(self());
        model.doScoring(train,trainScoreFrame,validScoreFrame,self(),validAdapter.getValidAdaptor());
        assert(best_model.error() == model.error());
      }
    }
    Log.info(model);
    Log.info("Finished training the Deep Learning model.");
  }
 catch (  RuntimeException ex) {
    model=DKV.get(dest()).get();
    _state=JobState.CANCELLED;
    Log.info("Deep Learning model building was cancelled.");
    throw ex;
  }
 finally {
    if (model != null)     model.unlock(self());
    unlock_data();
    for (    Frame f : _delete_me)     f.delete();
  }
  return model;
}
