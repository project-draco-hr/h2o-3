{
  System.err.printf("\n" + "Usage: h2odriver\n" + "          [generic Hadoop ToolRunner options]\n"+ "          [-h | -help]\n"+ "          [-jobname <name of job in jobtracker (defaults to: 'H2O_nnnnn')>]\n"+ "              (Note nnnnn is chosen randomly to produce a unique name)\n"+ "          [-driverif <ip address of mapper->driver callback interface>]\n"+ "          [-driverport <port of mapper->driver callback interface>]\n"+ "          [-network <IPv4network1Specification>[,<IPv4network2Specification> ...]\n"+ "          [-timeout <seconds>]\n"+ "          [-disown]\n"+ "          [-notify <notification file name>]\n"+ "          -mapperXmx <per mapper Java Xmx heap size>\n"+ "          [-extramempercent <0 to 20>]\n"+ "          -n | -nodes <number of H2O nodes (i.e. mappers) to create>\n"+ "          [-nthreads <maximum typical worker threads, i.e. cpus to use>]\n"+ "          [-baseport <starting HTTP port for H2O nodes; default is 54321>]\n"+ "          [-ea]\n"+ "          [-verbose:gc]\n"+ "          [-XX:+PrintGCDetails]\n"+ "          [-license <license file name (local filesystem, not hdfs)>]\n"+ "          -o | -output <hdfs output dir>\n"+ "\n"+ "Notes:\n"+ "          o  Each H2O node runs as a mapper.\n"+ "          o  Only one mapper may be run per host.\n"+ "          o  There are no combiners or reducers.\n"+ "          o  Each H2O cluster should have a unique jobname.\n"+ "          o  -mapperXmx, -nodes and -output are required.\n"+ "\n"+ "          o  -mapperXmx is set to both Xms and Xmx of the mapper to reserve\n"+ "             memory up front.\n"+ "          o  -extramempercent is a percentage of mapperXmx.  (Default: " + DEFAULT_EXTRA_MEM_PERCENT + ")\n"+ "             Extra memory for internal JVM use outside of Java heap.\n"+ "                 mapreduce.map.memory.mb = mapperXmx * (1 + extramempercent/100)\n"+ "          o  -libjars with an h2o.jar is required.\n"+ "          o  -driverif and -driverport let the user optionally specify the\n"+ "             network interface and port (on the driver host) for callback\n"+ "             messages from the mapper to the driver.\n"+ "          o  -network allows the user to specify a list of networks that the\n"+ "             H2O nodes can bind to.  Use this if you have multiple network\n"+ "             interfaces on the hosts in your Hadoop cluster and you want to\n"+ "             force H2O to use a specific one.\n"+ "             (Example network specification: '10.1.2.0/24' allows 256 legal\n"+ "             possibilities.)\n"+ "          o  -timeout specifies how many seconds to wait for the H2O cluster\n"+ "             to come up before giving up.  (Default: "+ DEFAULT_CLOUD_FORMATION_TIMEOUT_SECONDS+ " seconds\n"+ "          o  -disown causes the driver to exit as soon as the cloud forms.\n"+ "             Otherwise, Ctrl-C of the driver kills the Hadoop Job.\n"+ "          o  -notify specifies a file to write when the cluster is up.\n"+ "             The file contains one line with the IP and port of the embedded\n"+ "             web server for one of the H2O nodes in the cluster.  e.g.\n"+ "                 192.168.1.100:54321\n"+ "          o  All mappers must start before the H2O cloud is considered up.\n"+ "\n"+ "Examples:\n"+ "          hadoop jar h2odriver.jar -nodes 1 -mapperXmx 1g -output hdfsOutputDir\n"+ "          hadoop jar h2odriver.jar -nodes 1 -mapperXmx 1g -notify notify.txt -disown -output hdfsOutputDir\n"+ "\n"+ "Exit value:\n"+ "          0 means the cluster exited successfully with an orderly Shutdown.\n"+ "              (From the Web UI or the REST API.)\n"+ "\n"+ "          non-zero means the cluster exited with a failure.\n"+ "              (Note that Ctrl-C is treated as a failure.)\n"+ "\n");
  System.exit(1);
}
