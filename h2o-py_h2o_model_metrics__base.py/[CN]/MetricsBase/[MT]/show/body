def show(self):
    '\n    Display a short summary of the metrics.\n    :return: None\n    '
    metric_type = self._metric_json['__meta']['schema_type']
    types_w_glm = ['ModelMetricsRegressionGLM', 'ModelMetricsBinomialGLM']
    types_w_clustering = ['ModelMetricsClustering']
    types_w_mult = ['ModelMetricsMultinomial']
    types_w_bin = ['ModelMetricsBinomial', 'ModelMetricsBinomialGLM']
    types_w_r2 = ((['ModelMetricsBinomial', 'ModelMetricsRegression'] + types_w_glm) + types_w_mult)
    types_w_mean_residual_deviance = ['ModelMetricsRegressionGLM', 'ModelMetricsRegression']
    types_w_mean_absolute_error = ['ModelMetricsRegressionGLM', 'ModelMetricsRegression']
    types_w_logloss = (types_w_bin + types_w_mult)
    types_w_dim = ['ModelMetricsGLRM']
    print()
    print(((metric_type + ': ') + self._algo))
    reported_on = '** Reported on {} data. **'
    if self._on_train:
        print(reported_on.format('train'))
    elif self._on_valid:
        print(reported_on.format('validation'))
    elif self._on_xval:
        print(reported_on.format('cross-validation'))
    else:
        print(reported_on.format('test'))
    print()
    print(('MSE: ' + str(self.mse())))
    print(('RMSE: ' + str(self.rmse())))
    if (metric_type in types_w_mean_absolute_error):
        print(('MAE: ' + str(self.mae())))
    if (metric_type in types_w_r2):
        print(('R^2: ' + str(self.r2())))
    if (metric_type in types_w_mean_residual_deviance):
        print(('Mean Residual Deviance: ' + str(self.mean_residual_deviance())))
    if (metric_type in types_w_logloss):
        print(('LogLoss: ' + str(self.logloss())))
    if (metric_type == 'ModelMetricsBinomial'):
        print(('Mean Per-Class Error: ' + str(self.mean_per_class_error()[0][1])))
    if (metric_type == 'ModelMetricsMultinomial'):
        print(('Mean Per-Class Error: ' + str(self.mean_per_class_error())))
    if (metric_type in types_w_glm):
        print(('Null degrees of freedom: ' + str(self.null_degrees_of_freedom())))
        print(('Residual degrees of freedom: ' + str(self.residual_degrees_of_freedom())))
        print(('Null deviance: ' + str(self.null_deviance())))
        print(('Residual deviance: ' + str(self.residual_deviance())))
        print(('AIC: ' + str(self.aic())))
    if (metric_type in types_w_bin):
        print(('AUC: ' + str(self.auc())))
        print(('Gini: ' + str(self.giniCoef())))
        self.confusion_matrix().show()
        self._metric_json['max_criteria_and_metric_scores'].show()
        if self.gains_lift():
            print(self.gains_lift())
    if (metric_type in types_w_mult):
        self.confusion_matrix().show()
        self.hit_ratio_table().show()
    if (metric_type in types_w_clustering):
        print(('Total Within Cluster Sum of Square Error: ' + str(self.tot_withinss())))
        print(('Total Sum of Square Error to Grand Mean: ' + str(self.totss())))
        print(('Between Cluster Sum of Square Error: ' + str(self.betweenss())))
        self._metric_json['centroid_stats'].show()
    if (metric_type in types_w_dim):
        print(('Sum of Squared Error (Numeric): ' + str(self.num_err())))
        print(('Misclassification Error (Categorical): ' + str(self.cat_err())))
