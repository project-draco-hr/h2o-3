def show(self):
    u'\n    Display a short summary of the metrics.\n    :return: None\n    '
    metric_type = self._metric_json[u'__meta'][u'schema_type']
    types_w_glm = [u'ModelMetricsRegressionGLM', u'ModelMetricsBinomialGLM']
    types_w_clustering = [u'ModelMetricsClustering']
    types_w_mult = [u'ModelMetricsMultinomial']
    types_w_bin = [u'ModelMetricsBinomial', u'ModelMetricsBinomialGLM']
    types_w_r2 = (([u'ModelMetricsBinomial', u'ModelMetricsRegression'] + types_w_glm) + types_w_mult)
    types_w_mean_residual_deviance = [u'ModelMetricsRegressionGLM', u'ModelMetricsRegression']
    types_w_mean_absolute_error = [u'ModelMetricsRegressionGLM', u'ModelMetricsRegression']
    types_w_logloss = (types_w_bin + types_w_mult)
    types_w_dim = [u'ModelMetricsGLRM']
    print()
    print(((metric_type + u': ') + self._algo))
    reported_on = u'** Reported on {} data. **'
    if self._on_train:
        print(reported_on.format(u'train'))
    elif self._on_valid:
        print(reported_on.format(u'validation'))
    elif self._on_xval:
        print(reported_on.format(u'cross-validation'))
    else:
        print(reported_on.format(u'test'))
    print()
    print((u'MSE: ' + str(self.mse())))
    print((u'RMSE: ' + str(self.rmse())))
    if (metric_type in types_w_mean_absolute_error):
        print((u'MAE: ' + str(self.mae())))
    if (metric_type in types_w_r2):
        print((u'R^2: ' + str(self.r2())))
    if (metric_type in types_w_mean_residual_deviance):
        print((u'Mean Residual Deviance: ' + str(self.mean_residual_deviance())))
    if (metric_type in types_w_logloss):
        print((u'LogLoss: ' + str(self.logloss())))
    if (metric_type == u'ModelMetricsBinomial'):
        print((u'Mean Per-Class Error: ' + str(self.mean_per_class_error()[0][1])))
    if (metric_type == u'ModelMetricsMultinomial'):
        print((u'Mean Per-Class Error: ' + str(self.mean_per_class_error())))
    if (metric_type in types_w_glm):
        print((u'Null degrees of freedom: ' + str(self.null_degrees_of_freedom())))
        print((u'Residual degrees of freedom: ' + str(self.residual_degrees_of_freedom())))
        print((u'Null deviance: ' + str(self.null_deviance())))
        print((u'Residual deviance: ' + str(self.residual_deviance())))
        print((u'AIC: ' + str(self.aic())))
    if (metric_type in types_w_bin):
        print((u'AUC: ' + str(self.auc())))
        print((u'Gini: ' + str(self.giniCoef())))
        self.confusion_matrix().show()
        self._metric_json[u'max_criteria_and_metric_scores'].show()
        if self.gains_lift():
            print(self.gains_lift())
    if (metric_type in types_w_mult):
        self.confusion_matrix().show()
        self.hit_ratio_table().show()
    if (metric_type in types_w_clustering):
        print((u'Total Within Cluster Sum of Square Error: ' + str(self.tot_withinss())))
        print((u'Total Sum of Square Error to Grand Mean: ' + str(self.totss())))
        print((u'Between Cluster Sum of Square Error: ' + str(self.betweenss())))
        self._metric_json[u'centroid_stats'].show()
    if (metric_type in types_w_dim):
        print((u'Sum of Squared Error (Numeric): ' + str(self.num_err())))
        print((u'Misclassification Error (Categorical): ' + str(self.cat_err())))
