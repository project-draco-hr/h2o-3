def hdfs_orc_parser():
    hadoop_namenode_is_accessible = pyunit_utils.hadoop_namenode_is_accessible()
    if hadoop_namenode_is_accessible:
        hdfs_name_node = pyunit_utils.hadoop_namenode()
        if pyunit_utils.cannaryHDFSTest(hdfs_name_node, '/datasets/orc_parser/orc/orc_split_elim.orc'):
            print('Your hive-exec version is too old.  Orc parser test {0} is skipped.'.format('pyunit_INTERNAL_HDFS_import_folder_orc.py'))
            pass
        else:
            mix_folder = '/datasets/csv_orc_same_milsongs'
            url_csv1 = 'hdfs://{0}{1}'.format(hdfs_name_node, mix_folder)
            multi_file_mixed = h2o.import_file(url_csv1)
    else:
        raise EnvironmentError
